{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AiDM 2019: Assignment 1 - Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auke Bruinsma, s1594443 and Simon van Wageningen, s2317079"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As instructed, we have divided the first assignment of AiDM into two parts: The first on the naive models and this part on the matrix factorization. The structure of this part will be as follows: Before each cell of code we'll provide background info in markdown cells if necessary. If a cell produces relevant output we'll write this down. At the end there will be a short conclusion/discussion section where we compare our results of the naive models and matrix factorization with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we import the three datasets using pandas. We have given each columns the names that are found in the readme file so that each column can be accessed with, for example, ratings['UserID']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets and infer a header with the correct column labels.\n",
    "ratings = pd.read_csv(filepath_or_buffer='data/ml-1m/ratings.dat',sep='::',header=None,names=['UserID','MovieID','Rating','Timestamp'],engine='python')\n",
    "users = pd.read_csv(filepath_or_buffer='data/ml-1m/users.dat',sep='::',header=None,names=['UserID','Gender','Age','Occupation','Zip-code'],engine='python')\n",
    "movies = pd.read_csv(filepath_or_buffer='data/ml-1m/movies.dat',sep='::',header=None,names=['MovieID','Title','Genres'],engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the array $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported all necessary packages and datasets, we can start with the assignment. After a quick look at the data, we noticed the following things:\n",
    "\n",
    "- There are approximately 6000 users.\n",
    "- There are approximately 4000 movies.\n",
    "- Not every users has rated each movie.\n",
    "- Sometimes the ['MovieID'] column skips a number. This may mean that a movie is deleted from the database, or that no one has rated that movie. \n",
    "\n",
    "In order to complete the matrix factorization, we will create a matrix called $X$. This matrix has approximately the size $(6000,4000)$, where $X_{i,j}$ denotes how the $i_{th}$ user will rate the $j_{th}$ movie. Because of the last two points in the previous enumeration, there are a lot of empty elements in this matrix. Approximately 4.2 percent of the matrix $X$ has elements that are not equal to zero, which means 4.2 percent has been rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array X with at X[i][j] the ratings for how the ith user would rate the jth movies\n",
    "X = np.zeros((users['UserID'][len(users)-1]+1,movies['MovieID'][len(movies)-1]+1))\n",
    "\n",
    "# Fill array.\n",
    "for k in range(len(ratings)):\n",
    "    X[ratings['UserID'][k]][ratings['MovieID'][k]] = ratings['Rating'][k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we compute the percentage filled of the matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage filled: 4.188467095557036 %\n"
     ]
    }
   ],
   "source": [
    "# To get a better overview, here we print the number of matrix elements that is known.\n",
    "print('Percentage filled: {0} %'.format(100*len(ratings)/(len(X)*len(X[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact shape of the matrix $X$ is (6041,3953), it is also printed for a quick overview. You can see that that most elements are zero and only two elements have a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X: (6041, 3953)\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 3. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Shape X: {0}\\n'.format(X.shape))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the imported data in a matrix called $X$. This matrix will form the basis of the computations that are needed to perform the matrix factorization. However, first we need to set up the N-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. N-fold cross-validation:\n",
    "\n",
    "1. Split your data in $N$ parts (equal size);\n",
    "2. Develop $N$ models on all combinations of $(N-1)$ parts;\n",
    "3. Test each model on the remaining parts (test sets);\n",
    "4. Average the errors over these $N$ test sets;\n",
    "5. The average error is a realistic estimator of the error made by your model on the fresh data.\n",
    "\n",
    "#### In practice:\n",
    "- $N=5$ (5-fold cross-validation) or $(N=10)$ (10-fold cross-validation)\n",
    "- Errors also measured on the training sets/folds\n",
    "- Standard deviation of errors says something about 'model stability'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text in the previous markdown cell is taken from the slides. The idea of N-fold cross validation is to create your own training and testing set so that you can test the accuracy of your model. You divide all your data into $N$ parts, in our case 5 parts. Then 4/5 is used as a training set and 1/5 as a testing set. You repeat this process for each one-fifth of the data, so that each one-fifth is used for testing, and each 4/5 is used for the training set. This will give an accurate outcome of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The splitting of the data in 5 parts is done in the following way: All the indices of the elements of the matrix $X$ which are not equal to zero, are stored in a list called non_zero_indices. Each element of this array contains the $i$-coordinate, $j$-coordinate, and also the rating. This means the size of this array is $(1000209,3)$, since there are $1000209$ ratings present in the matrix $X$. Next, the non_zero_indices array is randomly shuffled, to make the results more valid. The array is then split into 5 parts, and this array is returned by the function k_fold_cross_validation. The size of this list is $(n=5,~10^6/(n=5),3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array where all the indices will be stored which are not zero.\n",
    "non_zero_indices = []\n",
    "for i in range(len(X)):\n",
    "    for j in range(len(X[i])):\n",
    "        if X[i][j] != 0:\n",
    "            non_zero_indices.append((i,j,X[i][j])) # Has length 1.000.209."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above coding cell creates the array with the indices of the elements that have a rating. The code cell below is the function that randomly shuffles the data and splits it into 5 parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(data,k):\n",
    "    np.random.shuffle(data)\n",
    "    splitted_data = []\n",
    "    for i in range(k):\n",
    "        splitted_data.append(data[int(len(data)/k*i):int(len(data)/k*(i+1))])\n",
    "        print('Size set {0}: {1}'.format(i+1,np.shape(splitted_data[i])))\n",
    "    return splitted_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size set 1: (200041, 3)\n",
      "Size set 2: (200042, 3)\n",
      "Size set 3: (200042, 3)\n",
      "Size set 4: (200042, 3)\n",
      "Size set 5: (200042, 3)\n"
     ]
    }
   ],
   "source": [
    "folded_data = k_fold_cross_validation(non_zero_indices,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is some output that displays the size of each of the 5 sets. Each set contains approximately $2*10^5$ datapoints/ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have set up our data in 5 different parts. Next is the process called matrix factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Matrix factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following equations are taken from the gravity-tikk paper page 24.\n",
    "\n",
    "The matrix $X$ can be approximated as the product of two matrices:\n",
    "\n",
    "$$X \\approx UM $$\n",
    "\n",
    "$X$ has shape $(i,j)$ where $i$ denotes the $i$th user and $j$ denotes the $j$th movie. The element $(i,j)$ contains the rating the user has given the movie. The matrices $U$ and $M$ have shapes $(i,k)$ and $(k,j)$, respectively. $k$ is a factor which can be chosen. In the code this will simply be called $k$ and experimentation will be done with this value. Now, instead of having a single matrix with approximate size $(6000,4000)$, you have two matrices with sizes $(6000,k)$ and $(k,4000)$, which is much less data. The key idea is that the product of the matrices $U$ and $M$ will give accurate predictions of what rating a certain user will give to movie he hasn't rated yet, based on his/hers known ratings.\n",
    "\n",
    "How do we obtain the matrix elements of $U$ and $M$? We initialize the matrices with random weight produced by numpy.random.randn, which are all values obtained from a gaussian distribution. The elements of $U$ and $M$ are then constantly updated over several iterations. They are computed with the following equations.\n",
    "\n",
    "$$ \\hat{x}_{ij} = \\sum_{k=1}^{K} = u_{ik}m_{kj} $$\n",
    "\n",
    "$ \\hat{x}_{ij} $ denotes the predicted values of what user $i$ will rate movie $j$. Next the error of the predicted value compared to the known value is computed. This is done only for values which are known, so for the total $1000209$ ratings given by the $6041$ users.\n",
    "\n",
    "$$ e_{ij} = x_{ij}-\\hat{x}_{ij} $$\n",
    "\n",
    "The total error of all these ratings is just the sum of the errors:\n",
    "\n",
    "$$ SE = \\sum_{ij} e^2_{ij} $$\n",
    "\n",
    "What you want, is to minimize the total error over time. The new values for the elements in the matrices $U$ and $M$ are computed with the two following algorithms:\n",
    "\n",
    "$$ u`_{ik}  = u_{ik} + \\eta \\cdot (2 e_{ij} \\cdot m_{kj} - \\lambda \\cdot u_{ik} ) $$\n",
    "$$ m`_{kj}  = m_{kj} + \\eta \\cdot (2 e_{ij} \\cdot u_{ik} - \\lambda \\cdot m_{kj} ) $$\n",
    "\n",
    "$ u`_{ik} $ is the updated parameter value. $\\eta$ is the learning rate, so it specifies how fast the algorithm learns. $\\lambda$ is the regularization factor to prevent large weights.\n",
    "\n",
    "After these computations are performed on the training set, the new matrices $U$ and $M$ are computed and the equations that compute the predicted matrix values $\\hat{x}_{ij}$ and the (total) error is computed on the test set. From this error the RMSE can be computed. This is just the square root of the mean of the total error. This value usually starts out high, around 3 are 4, then rapidly decreases in the first few iterations and then slowly drops to 0.9 or 0.8, depending on the initial parameter values for the learning rate and regularization value. The iteration process will be stopped of the error increases. That means no further improvement can be obtained using the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_fac(indices,X,test_set):\n",
    "    # Initial parameters. Set eta and lambda to some small positive values.\n",
    "    eta = 0.01 # Learning rate (eq. 6 gravity-tikk).\n",
    "    lamda = 0.1 # The regularization factor lambda (eq. 6 gravity-tikk).\n",
    "    k = 10 # The parameter that sets the shape of the matrices U and M.\n",
    "    n_iter = 100 # Number of maximum iterations.\n",
    "\n",
    "    # Initialize the two matrices (eq. 1 gravity-tikk)\n",
    "    U = np.random.randn(users['UserID'][len(users)-1]+1,k) # Initialize the weights of U ...\n",
    "    M = np.random.randn(k,movies['MovieID'][len(movies)-1]+1) # ... and M randomly.\n",
    "    \n",
    "    prev_RMSE = 10e10+1; RMSE = 10e10 # Set some initial values for the RMSE.\n",
    "    prev_RMSE_test = 10e10+1; RMSE_test = 10e10\n",
    "    \n",
    "    total_SE_test = []\n",
    "    \n",
    "    for n in range(n_iter):\n",
    "        if RMSE_test < prev_RMSE_test: # Only continue the loop if there is improvement.\n",
    "            prev_RMSE_test = RMSE_test\n",
    "            SE_test = 0; SE = 0 # The total squared error (which is equivalent to minimize RMSE).\n",
    "            for i in range(len(indices)): # Loop until the terminal condition is met.\n",
    "                if i != test_set: # Don't use the testing set for training.\n",
    "                    for j in range(len(indices[i])):\n",
    "                        x_hat_ij = np.dot(U[indices[i][j][0],:],M[:,indices[i][j][1]]) # Eq. 3 gravity-tikk\n",
    "                        e_ij = X[indices[i][j][0]][indices[i][j][1]]-x_hat_ij # Eq. 4 gravity-tikk\n",
    "                        SE += e_ij**2; # Total error.\n",
    "                        temp = U[indices[i][j][0],:]+eta*(2*e_ij*M[:,indices[i][j][1]]-lamda*U[indices[i][j][0],:])\n",
    "                        M[:,indices[i][j][1]] += eta*(2*e_ij*U[indices[i][j][0],:]-lamda*M[:,indices[i][j][1]])\n",
    "                        U[indices[i][j][0],:] = temp # Update factorized matrices.\n",
    "            X_pred = np.dot(U,M)\n",
    "            for j in range(len(indices[test_set])):\n",
    "                SE_test += (X[indices[test_set][j][0]][indices[test_set][j][1]]-X_pred[indices[test_set][j][0]][indices[test_set][j][1]])**2  \n",
    "                RMSE_test = (SE_test/len(indices[test_set]))**0.5\n",
    "            RMSE = np.sqrt(SE/800168) # Compute the root mean squared error. (Use a fixed number for efficiency.)\n",
    "            total_SE_test.append(SE_test) # For statistics.\n",
    "            sys.stdout.write('\\rIterations: {0}\\n'.format(n)) # Overview of the process.\n",
    "            sys.stdout.write('\\rSE_train: {0}. RMSE_train: {1}\\n'.format(SE,RMSE)) # Overview of the process.\n",
    "            sys.stdout.write('\\rSE_test:  {0}. RMSE_test:  {1}\\n\\n'.format(SE_test,RMSE_test)) # Overview of the process.        \n",
    "        else:\n",
    "            print('\\nError increased. Process terminated.\\n')\n",
    "            break;\n",
    "            \n",
    "    return U,M,total_SE_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\n",
      "SE_train: 14064515.323242577. RMSE_train: 4.19248768560201\n",
      "SE_test:  2899222.06207733. RMSE_test:  3.806985581381573\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 7620082.536808458. RMSE_train: 3.085952578915223\n",
      "SE_test:  1107361.1546118236. RMSE_test:  2.3528006631485407\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 2912483.3763803593. RMSE_train: 1.9078364327441928\n",
      "SE_test:  562710.1741828651. RMSE_test:  1.677192359629935\n",
      "\n",
      "Iterations: 3\n",
      "SE_train: 1693423.4522644007. RMSE_train: 1.4547628277505065\n",
      "SE_test:  393731.3231178715. RMSE_test:  1.402944447830704\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 1253417.0734061184. RMSE_train: 1.2515759620798044\n",
      "SE_test:  318899.61216077214. RMSE_test:  1.2626049483890212\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 1043114.7802550715. RMSE_train: 1.14176167179436\n",
      "SE_test:  278771.76077781897. RMSE_test:  1.1804969806819532\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 925903.1308480541. RMSE_train: 1.075702521619204\n",
      "SE_test:  254630.56191044566. RMSE_test:  1.128225095767485\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 853834.196942427. RMSE_train: 1.0329901556932013\n",
      "SE_test:  238921.09813286655. RMSE_test:  1.0928680829504323\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 806268.8210991183. RMSE_train: 1.003804973709832\n",
      "SE_test:  228085.56161533244. RMSE_test:  1.0677987021403716\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 773107.7045968845. RMSE_train: 0.982945437235589\n",
      "SE_test:  220264.5227110184. RMSE_test:  1.0493316390412089\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 748947.4014533858. RMSE_train: 0.967464570101101\n",
      "SE_test:  214408.96910576112. RMSE_test:  1.0352898731171492\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 730694.3597577178. RMSE_train: 0.9556025233844774\n",
      "SE_test:  209890.79546450585. RMSE_test:  1.0243236223730476\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 716478.6349020593. RMSE_train: 0.9462611993913228\n",
      "SE_test:  206315.34006404234. RMSE_test:  1.0155615542347847\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 705117.7475300533. RMSE_train: 0.9387289970301839\n",
      "SE_test:  203424.463197524. RMSE_test:  1.0084214637980724\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 695834.7028317953. RMSE_train: 0.9325292275741739\n",
      "SE_test:  201043.4593508132. RMSE_test:  1.002502503460131\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 688101.7310752941. RMSE_train: 0.9273330443068198\n",
      "SE_test:  199050.5518586828. RMSE_test:  0.9975213152081932\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 681549.7879972634. RMSE_train: 0.9229075607772286\n",
      "SE_test:  197358.63790238556. RMSE_test:  0.9932728418564367\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 675914.1105838894. RMSE_train: 0.9190839178376347\n",
      "SE_test:  195903.9763878207. RMSE_test:  0.9896055383430269\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 671000.3601086461. RMSE_train: 0.9157370526097587\n",
      "SE_test:  194638.96204176053. RMSE_test:  0.9864052646670329\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 666662.9445963213. RMSE_train: 0.9127725447582898\n",
      "SE_test:  193527.38498493028. RMSE_test:  0.9835845667819565\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 662790.7761030503. RMSE_train: 0.9101178627401818\n",
      "SE_test:  192541.24668882808. RMSE_test:  0.9810753891091762\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 659297.6952630933. RMSE_train: 0.9077164148400176\n",
      "SE_test:  191658.57604837194. RMSE_test:  0.9788240242584028\n",
      "\n",
      "Iterations: 22\n",
      "SE_train: 656115.9003207331. RMSE_train: 0.9055234293699294\n",
      "SE_test:  190861.9031649354. RMSE_test:  0.976787552372864\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 653191.354565852. RMSE_train: 0.9035030528317848\n",
      "SE_test:  190137.17473858033. RMSE_test:  0.9749312914422122\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 650480.5232894606. RMSE_train: 0.9016262744755571\n",
      "SE_test:  189472.97152709507. RMSE_test:  0.9732269456013372\n",
      "\n",
      "Iterations: 25\n",
      "SE_train: 647948.0204407967. RMSE_train: 0.8998694210307769\n",
      "SE_test:  188859.93583319362. RMSE_test:  0.9716512426831962\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 645564.8874365884. RMSE_train: 0.8982130505019821\n",
      "SE_test:  188290.34709097503. RMSE_test:  0.9701849191806204\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 643307.3167917919. RMSE_train: 0.8966411284755749\n",
      "SE_test:  187757.80309200098. RMSE_test:  0.9688119544867094\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 641155.6916288557. RMSE_train: 0.8951404060276265\n",
      "SE_test:  187256.97722960924. RMSE_test:  0.9675189853877254\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 639093.8507156012. RMSE_train: 0.8936999420842212\n",
      "SE_test:  186783.43078044703. RMSE_test:  0.9662948515466226\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 637108.5148126081. RMSE_train: 0.8923107293111828\n",
      "SE_test:  186333.46519073696. RMSE_test:  0.9651302364433304\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 635188.8283050361. RMSE_train: 0.8909653940088232\n",
      "SE_test:  185904.00353305586. RMSE_test:  0.9640173780159413\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 633325.9831670872. RMSE_train: 0.8896579487606697\n",
      "SE_test:  185492.4933404116. RMSE_test:  0.9629498303987626\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 631512.9019980637. RMSE_train: 0.8883835827871003\n",
      "SE_test:  185096.82527590162. RMSE_test:  0.9619222635011101\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 629743.9642137303. RMSE_train: 0.8871384797109774\n",
      "SE_test:  184715.26378460086. RMSE_test:  0.9609302912193812\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 628014.7650710569. RMSE_train: 0.8859196561060351\n",
      "SE_test:  184346.38713371384. RMSE_test:  0.9599703221191802\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 626321.9013803109. RMSE_train: 0.8847248169600659\n",
      "SE_test:  183989.03516128586. RMSE_test:  0.9590394286462686\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 624662.7806979268. RMSE_train: 0.8835522261416023\n",
      "SE_test:  183642.26368044. RMSE_test:  0.9581352324499133\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 623035.4526523326. RMSE_train: 0.8824005911980753\n",
      "SE_test:  183305.3048747964. RMSE_test:  0.9572558043415659\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 621438.461987107. RMSE_train: 0.8812689624270305\n",
      "SE_test:  182977.53322294378. RMSE_test:  0.9563995778875267\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 619870.7231185843. RMSE_train: 0.8801566462832687\n",
      "SE_test:  182658.4365585564. RMSE_test:  0.9555652757758346\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 618331.4157235443. RMSE_train: 0.8790631329638195\n",
      "SE_test:  182347.59186165803. RMSE_test:  0.9547518480393565\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 616819.9003342924. RMSE_train: 0.87798803761161\n",
      "SE_test:  182044.64533041455. RMSE_test:  0.9539584210723757\n",
      "\n",
      "Iterations: 43\n",
      "SE_train: 615335.6523287579. RMSE_train: 0.8769310541402141\n",
      "SE_test:  181749.2962377999. RMSE_test:  0.9531842562393691\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 613878.2122123821. RMSE_train: 0.8758919203119203\n",
      "SE_test:  181461.2840532901. RMSE_test:  0.9524287167930381\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 612447.1497831095. RMSE_train: 0.8748703924617233\n",
      "SE_test:  181180.3783145938. RMSE_test:  0.9516912418152857\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 611042.0396780615. RMSE_train: 0.8738662281715559\n",
      "SE_test:  180906.3707668399. RMSE_test:  0.9509713259658903\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 609662.4458907408. RMSE_train: 0.872879175242465\n",
      "SE_test:  180639.06933758044. RMSE_test:  0.9502685039455091\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 608307.9130836299. RMSE_train: 0.8719089654621555\n",
      "SE_test:  180378.2935779551. RMSE_test:  0.9495823387327077\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 606977.9628317194. RMSE_train: 0.8709553118714192\n",
      "SE_test:  180123.8712623229. RMSE_test:  0.9489124128097081\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 605672.093277568. RMSE_train: 0.8700179084669113\n",
      "SE_test:  179875.63589749648. RMSE_test:  0.9482583217400777\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 604389.7810098802. RMSE_train: 0.8690964315050584\n",
      "SE_test:  179633.42494223564. RMSE_test:  0.9476196695870921\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 603130.4842740739. RMSE_train: 0.8681905417770098\n",
      "SE_test:  179397.0785791441. RMSE_test:  0.9469960657670452\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 601893.6468710529. RMSE_train: 0.8672998873970489\n",
      "SE_test:  179166.4389135771. RMSE_test:  0.9463871230144834\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 600678.7022969961. RMSE_train: 0.8664241067845201\n",
      "SE_test:  178941.3494997644. RMSE_test:  0.945792456201639\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 599485.0778291725. RMSE_train: 0.865562831626458\n",
      "SE_test:  178721.6551139885. RMSE_test:  0.9452116818044736\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 598312.1983711732. RMSE_train: 0.8647156896847248\n",
      "SE_test:  178507.20171069502. RMSE_test:  0.9446444178487796\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 597159.4899504839. RMSE_train: 0.8638823073680224\n",
      "SE_test:  178297.83650939018. RMSE_test:  0.9440902842004482\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 596026.3828169199. RMSE_train: 0.8630623120289268\n",
      "SE_test:  178093.40817094338. RMSE_test:  0.9435489030916994\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 594912.3141231947. RMSE_train: 0.862255333969696\n",
      "SE_test:  177893.7670302265. RMSE_test:  0.9430198997964958\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 593816.7301963238. RMSE_train: 0.8614610081605567\n",
      "SE_test:  177698.7653590978. RMSE_test:  0.9425029033866665\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 61\n",
      "SE_train: 592739.0884203017. RMSE_train: 0.86067897568289\n",
      "SE_test:  177508.2576400182. RMSE_test:  0.9419975475165994\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 591678.8587589926. RMSE_train: 0.859908884916167\n",
      "SE_test:  177322.10083544877. RMSE_test:  0.9415034711970303\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 590635.5249540439. RMSE_train: 0.8591503924920257\n",
      "SE_test:  177140.15464233307. RMSE_test:  0.9410203195293411\n",
      "\n",
      "Iterations: 64\n",
      "SE_train: 589608.5854315872. RMSE_train: 0.8584031640384123\n",
      "SE_test:  176962.28172442308. RMSE_test:  0.9405477443808613\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 588597.5539537853. RMSE_train: 0.8576668747386403\n",
      "SE_test:  176788.34791787594. RMSE_test:  0.940085404988718\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 587601.9600471273. RMSE_train: 0.856941209727455\n",
      "SE_test:  176618.2224075191. RMSE_test:  0.939632968484996\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 586621.3492397607. RMSE_train: 0.8562258643466908\n",
      "SE_test:  176451.7778730104. RMSE_test:  0.9391901103408525\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 585655.2831361599. RMSE_train: 0.8555205442804081\n",
      "SE_test:  176288.89060502534. RMSE_test:  0.9387565147296543\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 584703.3393549396. RMSE_train: 0.8548249655877501\n",
      "SE_test:  176129.44059264433. RMSE_test:  0.9383318748120132\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 583765.1113538218. RMSE_train: 0.854138854650602\n",
      "SE_test:  175973.31158356467. RMSE_test:  0.9379158929468375\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 582840.20816192. RMSE_train: 0.8534619480504554\n",
      "SE_test:  175820.39111910108. RMSE_test:  0.9375082808334527\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 581928.2540378153. RMSE_train: 0.8527939923877537\n",
      "SE_test:  175670.5705462975. RMSE_test:  0.9371087595908442\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 581028.8880697404. RMSE_train: 0.8521347440555102\n",
      "SE_test:  175523.74500932737. RMSE_test:  0.9367170597797234\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 580141.7637311168. RMSE_train: 0.8514839689768192\n",
      "SE_test:  175379.81342251875. RMSE_test:  0.936332921373571\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 579266.5484033127. RMSE_train: 0.8508414423149293\n",
      "SE_test:  175238.67842722486. RMSE_test:  0.9359560936845365\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 578402.9228762288. RMSE_train: 0.8502069481636796\n",
      "SE_test:  175100.2463346949. RMSE_test:  0.9355863352499222\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 577550.5808345792. RMSE_train: 0.8495802792241274\n",
      "SE_test:  174964.4270568838. RMSE_test:  0.935223413684426\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 576709.2283369458. RMSE_train: 0.8489612364726468\n",
      "SE_test:  174831.13402713393. RMSE_test:  0.9348671055033193\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 575878.5832942446. RMSE_train: 0.8483496288254818\n",
      "SE_test:  174700.28411248414. RMSE_test:  0.9345171959212836\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 575058.3749513179. RMSE_train: 0.847745272802603\n",
      "SE_test:  174571.79751901785. RMSE_test:  0.9341734786307161\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 574248.343376327. RMSE_train: 0.8471479921944371\n",
      "SE_test:  174445.59769197597. RMSE_test:  0.9338357555641752\n",
      "\n",
      "Iterations: 82\n",
      "SE_train: 573448.238960679. RMSE_train: 0.8465576177336182\n",
      "SE_test:  174321.6112116105. RMSE_test:  0.9335038366436325\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 572657.8219321113. RMSE_train: 0.8459739867738348\n",
      "SE_test:  174199.76768626747. RMSE_test:  0.9331775395205796\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 571876.861882478. RMSE_train: 0.8453969429770529\n",
      "SE_test:  174079.99964348655. RMSE_test:  0.9328566893091677\n",
      "\n",
      "Iterations: 85\n",
      "SE_train: 571105.137311978. RMSE_train: 0.8448263360105371\n",
      "SE_test:  173962.24242022002. RMSE_test:  0.9325411183154035\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 570342.4351906622. RMSE_train: 0.8442620212544302\n",
      "SE_test:  173846.43405289963. RMSE_test:  0.9322306657644281\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 569588.5505376842. RMSE_train: 0.8437038595203685\n",
      "SE_test:  173732.51516806486. RMSE_test:  0.9319251775278633\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 568843.2860189585. RMSE_train: 0.8431517167817549\n",
      "SE_test:  173620.42887429267. RMSE_test:  0.9316245058532877\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 568106.4515631457. RMSE_train: 0.8426054639157581\n",
      "SE_test:  173510.1206557074. RMSE_test:  0.9313285090966594\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 567377.863996024. RMSE_train: 0.8420649764572026\n",
      "SE_test:  173401.53826781426. RMSE_test:  0.9310370514597565\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 566657.3466932201. RMSE_train: 0.841530134364448\n",
      "SE_test:  173294.63163580562. RMSE_test:  0.9307500027331038\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 565944.7292503534. RMSE_train: 0.8410008217966655\n",
      "SE_test:  173189.35275572073. RMSE_test:  0.9304672380454795\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 565239.8471712196. RMSE_train: 0.8404769269030808\n",
      "SE_test:  173085.65559871492. RMSE_test:  0.9301886376207543\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 564542.5415724629. RMSE_train: 0.8399583416231364\n",
      "SE_test:  172983.49601857626. RMSE_test:  0.9299140865424985\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 563852.6589049876. RMSE_train: 0.8394449614978482\n",
      "SE_test:  172882.8316626697. RMSE_test:  0.9296434745269037\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 563170.0506910498. RMSE_train: 0.8389366854916627\n",
      "SE_test:  172783.6218863583. RMSE_test:  0.9293766957042098\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 562494.5732766443. RMSE_train: 0.8384334158246101\n",
      "SE_test:  172685.82767097186. RMSE_test:  0.9291136484088849\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 561826.0875984468. RMSE_train: 0.8379350578142822\n",
      "SE_test:  172589.41154528238. RMSE_test:  0.9288542349785004\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 561164.4589646354. RMSE_train: 0.8374415197272057\n",
      "SE_test:  172494.3375106035. RMSE_test:  0.9285983615616673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "U_0,M_0,SE_0 = mat_fac(folded_data,X,0) # Done with 0.001,0.01,10,100. Gives 0.928598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\n",
      "SE_train: 3563131.281638583. RMSE_train: 2.110208277981861\n",
      "SE_test:  218363.4999660699. RMSE_test:  1.044793627046562\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 758722.2108931269. RMSE_train: 0.9737574856461078\n",
      "SE_test:  194973.27318762627. RMSE_test:  0.9872520242032813\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 712640.6723028921. RMSE_train: 0.9437233765665682\n",
      "SE_test:  188592.10549669852. RMSE_test:  0.9709620281942815\n",
      "\n",
      "Iterations: 3\n",
      "SE_train: 693177.3835320486. RMSE_train: 0.930746908968955\n",
      "SE_test:  184516.1861338203. RMSE_test:  0.9604123282954209\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 677328.8656294869. RMSE_train: 0.9200452817875571\n",
      "SE_test:  180999.01673359226. RMSE_test:  0.9512148010309935\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 662990.4625445812. RMSE_train: 0.9102549531444387\n",
      "SE_test:  178020.4685762454. RMSE_test:  0.9433556642644494\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 650482.453990434. RMSE_train: 0.9016276125397816\n",
      "SE_test:  175542.38310307692. RMSE_test:  0.9367667913899314\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 639624.8201966492. RMSE_train: 0.8940711151706139\n",
      "SE_test:  173458.641885889. RMSE_test:  0.9311903407800356\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 630178.0385136841. RMSE_train: 0.8874441735333362\n",
      "SE_test:  171697.29805732178. RMSE_test:  0.9264505041428821\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 621956.3304455386. RMSE_train: 0.8816360835391922\n",
      "SE_test:  170203.39982603633. RMSE_test:  0.9224112837568821\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 614759.0902048044. RMSE_train: 0.8765201209192556\n",
      "SE_test:  168924.8480768174. RMSE_test:  0.9189402199832516\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 608381.329086292. RMSE_train: 0.871961578734384\n",
      "SE_test:  167815.3036420367. RMSE_test:  0.9159173231132349\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 602650.1058470829. RMSE_train: 0.8678447268205188\n",
      "SE_test:  166838.19447222416. RMSE_test:  0.9132469536009836\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 597440.5469695863. RMSE_train: 0.8640855793816946\n",
      "SE_test:  165967.1388188249. RMSE_test:  0.910859820523187\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 592671.6781240032. RMSE_train: 0.8606300331755006\n",
      "SE_test:  165184.04961494313. RMSE_test:  0.9087084070955022\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 588293.3865364819. RMSE_train: 0.8574452394057014\n",
      "SE_test:  164476.63705304553. RMSE_test:  0.906760514836094\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 584273.1808684089. RMSE_train: 0.8545104660428858\n",
      "SE_test:  163836.24976985765. RMSE_test:  0.9049935641275634\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 580586.5151173071. RMSE_train: 0.8518102910475592\n",
      "SE_test:  163256.28958930436. RMSE_test:  0.90339036111024\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 577211.0306534033. RMSE_train: 0.8493305023565827\n",
      "SE_test:  162731.16768273283. RMSE_test:  0.9019362910725278\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 574123.9206559601. RMSE_train: 0.8470562112001271\n",
      "SE_test:  162255.73675142045. RMSE_test:  0.9006177911378006\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 571301.4417403948. RMSE_train: 0.8449715184746859\n",
      "SE_test:  161825.08839534235. RMSE_test:  0.8994218172012696\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 568719.5684687311. RMSE_train: 0.8430600233929224\n",
      "SE_test:  161434.55956462788. RMSE_test:  0.8983358844630832\n",
      "\n",
      "Iterations: 22\n",
      "SE_train: 566354.9508434918. RMSE_train: 0.8413055637481129\n",
      "SE_test:  161079.8088668798. RMSE_test:  0.8973482999205314\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 564185.6865525083. RMSE_train: 0.8396928251105409\n",
      "SE_test:  160756.88180697622. RMSE_test:  0.8964483627087204\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 562191.7557731533. RMSE_train: 0.8382077012082775\n",
      "SE_test:  160462.23782034218. RMSE_test:  0.8956264561848104\n",
      "\n",
      "Iterations: 25\n",
      "SE_train: 560355.1597348423. RMSE_train: 0.8368374318362051\n",
      "SE_test:  160192.74206734227. RMSE_test:  0.8948740394210201\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 558659.8661827975. RMSE_train: 0.8355705926510837\n",
      "SE_test:  159945.63512520381. RMSE_test:  0.8941835745257816\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 557091.6567474833. RMSE_train: 0.8343970068724407\n",
      "SE_test:  159718.49336239713. RMSE_test:  0.8935484256100835\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 555637.9411131606. RMSE_train: 0.8333076275032044\n",
      "SE_test:  159509.18879556557. RMSE_test:  0.8929627543012705\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 554287.5740370691. RMSE_train: 0.8322944176232584\n",
      "SE_test:  159315.85305168308. RMSE_test:  0.892421425100507\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 553030.6907871063. RMSE_train: 0.8313502411180065\n",
      "SE_test:  159136.84693051685. RMSE_test:  0.8919199251145009\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 551858.5644014415. RMSE_train: 0.830468767048745\n",
      "SE_test:  158970.73516718316. RMSE_test:  0.8914542973306309\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 550763.4821619553. RMSE_train: 0.8296443862540378\n",
      "SE_test:  158816.2651130621. RMSE_test:  0.8910210840704038\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 549738.6365887567. RMSE_train: 0.8288721370885989\n",
      "SE_test:  158672.34787427165. RMSE_test:  0.890617276695765\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 548778.0263996675. RMSE_train: 0.8281476372076972\n",
      "SE_test:  158538.04068913424. RMSE_test:  0.8902402682758981\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 547876.3641001312. RMSE_train: 0.8274670191463411\n",
      "SE_test:  158412.52976797012. RMSE_test:  0.8898878071287689\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 547028.9884311192. RMSE_train: 0.8268268685632305\n",
      "SE_test:  158295.11329969825. RMSE_test:  0.8895579504800699\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 546231.7813476424. RMSE_train: 0.8262241650706267\n",
      "SE_test:  158185.1847385888. RMSE_test:  0.8892490186165157\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 545481.0902495809. RMSE_train: 0.8256562263370376\n",
      "SE_test:  158082.21675719827. RMSE_test:  0.8889595506681015\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 544773.6567196966. RMSE_train: 0.825120656533985\n",
      "SE_test:  157985.74636492957. RMSE_test:  0.8886882634673279\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 544106.5530517926. RMSE_train: 0.824615300204975\n",
      "SE_test:  157895.3616616274. RMSE_test:  0.8884340148448824\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 543477.127486681. RMSE_train: 0.8241382023455002\n",
      "SE_test:  157810.69056248665. RMSE_test:  0.8881957723428894\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 542882.9584920568. RMSE_train: 0.8236875750298815\n",
      "SE_test:  157731.39164713572. RMSE_test:  0.8879725878064908\n",
      "\n",
      "Iterations: 43\n",
      "SE_train: 542321.8177995392. RMSE_train: 0.8232617704360291\n",
      "SE_test:  157657.14710150048. RMSE_test:  0.8877635777912054\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 541791.6413912723. RMSE_train: 0.8228592597116586\n",
      "SE_test:  157587.65756978217. RMSE_test:  0.8875679092927039\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 541290.5072876749. RMSE_train: 0.8224786168550554\n",
      "SE_test:  157522.63863513435. RMSE_test:  0.8873847900227563\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 540816.6188431452. RMSE_train: 0.8221185066629639\n",
      "SE_test:  157461.81860160007. RMSE_test:  0.887213462321113\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 540368.2922792124. RMSE_train: 0.8217776758064436\n",
      "SE_test:  157404.93724919623. RMSE_test:  0.8870531997874954\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 539943.9473223697. RMSE_train: 0.8214549461930039\n",
      "SE_test:  157351.7452645205. RMSE_test:  0.8869033058008439\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 539542.1000108274. RMSE_train: 0.8211492099175979\n",
      "SE_test:  157302.00409751743. RMSE_test:  0.8867631132268056\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 539161.3569458394. RMSE_train: 0.8208594252617988\n",
      "SE_test:  157255.48604932835. RMSE_test:  0.8866319847659331\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 538800.4104587557. RMSE_train: 0.8205846133463848\n",
      "SE_test:  157211.974448731. RMSE_test:  0.8865093135423003\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 538458.0343282188. RMSE_train: 0.8203238551648546\n",
      "SE_test:  157171.26382065727. RMSE_test:  0.8863945236612832\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 538133.0798090124. RMSE_train: 0.820076288820847\n",
      "SE_test:  157133.1599875433. RMSE_test:  0.8862870705700086\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 537824.471826941. RMSE_train: 0.8198411068622816\n",
      "SE_test:  157097.48007279515. RMSE_test:  0.8861864411342816\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 537531.205259049. RMSE_train: 0.8196175536539082\n",
      "SE_test:  157064.05239591832. RMSE_test:  0.8860921534029097\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 537252.3412602816. RMSE_train: 0.8194049227613833\n",
      "SE_test:  157032.7162623535. RMSE_test:  0.8860037560684126\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 536987.0036263084. RMSE_train: 0.8192025543414932\n",
      "SE_test:  157003.32165950435. RMSE_test:  0.8859208276569538\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 536734.3751967833. RMSE_train: 0.8190098325440057\n",
      "SE_test:  156975.7288744935. RMSE_test:  0.885842975491783\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 536493.6943134081. RMSE_train: 0.8188261829381182\n",
      "SE_test:  156949.80805096912. RMSE_test:  0.8857698344795404\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 536264.2513510319. RMSE_train: 0.8186510699792497\n",
      "SE_test:  156925.4387018764. RMSE_test:  0.8857010657676281\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 61\n",
      "SE_train: 536045.3853405264. RMSE_train: 0.8184839945321495\n",
      "SE_test:  156902.5091938025. RMSE_test:  0.8856363553171648\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 535836.4807025524. RMSE_train: 0.8183244914664294\n",
      "SE_test:  156880.9162166919. RMSE_test:  0.8855754124309141\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 535636.9641080613. RMSE_train: 0.8181721273379988\n",
      "SE_test:  156860.56425032482. RMSE_test:  0.8855179682687631\n",
      "\n",
      "Iterations: 64\n",
      "SE_train: 535446.3014791866. RMSE_train: 0.8180264981680759\n",
      "SE_test:  156841.36503705816. RMSE_test:  0.8854637743779612\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 535263.995141225. RMSE_train: 0.8178872273290734\n",
      "SE_test:  156823.23706817388. RMSE_test:  0.8854126012592114\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 535089.5811328542. RMSE_train: 0.8177539635438281\n",
      "SE_test:  156806.10508948102. RMSE_test:  0.8853642369848796\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 534922.6266785109. RMSE_train: 0.8176263790020808\n",
      "SE_test:  156789.89962992843. RMSE_test:  0.8853184858802208\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 534762.7278247107. RMSE_train: 0.8175041675963741\n",
      "SE_test:  156774.55655622968. RMSE_test:  0.885275167276356\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 534609.5072389785. RMSE_train: 0.8173870432770723\n",
      "SE_test:  156760.0166547717. RMSE_test:  0.8852341143388198\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 534462.6121677273. RMSE_train: 0.8172747385243415\n",
      "SE_test:  156746.2252415896. RMSE_test:  0.8851951729740879\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 534321.7125488364. RMSE_train: 0.8171670029344072\n",
      "SE_test:  156733.13180034023. RMSE_test:  0.885158200814072\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 534186.4992716965. RMSE_train: 0.817063601915059\n",
      "SE_test:  156720.6896475531. RMSE_test:  0.885123066276697\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 534056.6825780368. RMSE_train: 0.8169643154857272\n",
      "SE_test:  156708.85562432057. RMSE_test:  0.885089647700326\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 533931.9905952082. RMSE_train: 0.8168689371761546\n",
      "SE_test:  156697.58981283335. RMSE_test:  0.8850578325476484\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 533812.167992895. RMSE_train: 0.8167772730170926\n",
      "SE_test:  156686.85527650817. RMSE_test:  0.885027516675589\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 533696.9747555766. RMSE_train: 0.8166891406174484\n",
      "SE_test:  156676.61782184424. RMSE_test:  0.8849986036660626\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 533586.1850609008. RMSE_train: 0.8166043683206148\n",
      "SE_test:  156666.84578056773. RMSE_test:  0.8849710042135772\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 533479.5862561906. RMSE_train: 0.8165227944342606\n",
      "SE_test:  156657.50981016833. RMSE_test:  0.8849446355643944\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 533376.9779243338. RMSE_train: 0.8164442665270819\n",
      "SE_test:  156648.58271143388. RMSE_test:  0.8849194210033631\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 533278.1710307647. RMSE_train: 0.8163686407863469\n",
      "SE_test:  156640.03926126764. RMSE_test:  0.8848952893836296\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 533182.9871453007. RMSE_train: 0.8162957814316092\n",
      "SE_test:  156631.85605954996. RMSE_test:  0.8848721746957646\n",
      "\n",
      "Iterations: 82\n",
      "SE_train: 533091.2577297139. RMSE_train: 0.8162255601777453\n",
      "SE_test:  156624.0113885571. RMSE_test:  0.8848500156721405\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 533002.8234864462. RMSE_train: 0.8161578557439144\n",
      "SE_test:  156616.48508384195. RMSE_test:  0.8848287554234959\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 532917.5337612638. RMSE_train: 0.8160925534030308\n",
      "SE_test:  156609.2584154824. RMSE_test:  0.8848083411046214\n",
      "\n",
      "Iterations: 85\n",
      "SE_train: 532835.2459949863. RMSE_train: 0.8160295445681088\n",
      "SE_test:  156602.31397865654. RMSE_test:  0.8847887236062468\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 532755.8252186467. RMSE_train: 0.8159687264112438\n",
      "SE_test:  156595.63559278645. RMSE_test:  0.88476985727101\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 532679.1435884434. RMSE_train: 0.8159100015125044\n",
      "SE_test:  156589.2082084243. RMSE_test:  0.8847516996311855\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 532605.0799558957. RMSE_train: 0.8158532775352881\n",
      "SE_test:  156583.01782116978. RMSE_test:  0.8847342111661815\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 532533.5194697387. RMSE_train: 0.8157984669255387\n",
      "SE_test:  156577.051392112. RMSE_test:  0.8847173550783848\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 532464.3532067263. RMSE_train: 0.8157454866327033\n",
      "SE_test:  156571.2967741815. RMSE_test:  0.8847010970856285\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 532397.4778279928. RMSE_train: 0.8156942578499068\n",
      "SE_test:  156565.74264399838. RMSE_test:  0.884685405229122\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 532332.7952590315. RMSE_train: 0.8156447057718931\n",
      "SE_test:  156560.37843877188. RMSE_test:  0.8846702496955952\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 532270.2123910366. RMSE_train: 0.815596759369039\n",
      "SE_test:  156555.19429790936. RMSE_test:  0.8846556026526986\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 532209.6408012165. RMSE_train: 0.8155503511756383\n",
      "SE_test:  156550.18100896155. RMSE_test:  0.88464143809661\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 532150.9964912527. RMSE_train: 0.8155054170918496\n",
      "SE_test:  156545.32995765697. RMSE_test:  0.8846277317111553\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 532094.1996416087. RMSE_train: 0.8154618961975718\n",
      "SE_test:  156540.63308169032. RMSE_test:  0.8846144607375022\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 532039.1743810156. RMSE_train: 0.8154197305777536\n",
      "SE_test:  156536.0828280501. RMSE_test:  0.8846016038538222\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 531985.8485695337. RMSE_train: 0.8153788651579279\n",
      "SE_test:  156531.67211365426. RMSE_test:  0.8845891410642747\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 531934.1535945975. RMSE_train: 0.815339247549535\n",
      "SE_test:  156527.39428908445. RMSE_test:  0.8845770535967195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "U_0,M_0,SE_0 = mat_fac(folded_data,X,0) # Done with 0.01,0.1,10,100. Gives 0.884577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SE_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a254154f3276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSE_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSE_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total error over time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SE_0' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(np.arange(0,len(SE_0)),SE_0,'.')\n",
    "plt.xlabel('Iterations'); plt.ylabel('Total error')\n",
    "plt.title('Total error over time')\n",
    "plt.show(); plt.close()\n",
    "################ might be a good idea to plot the RMSE rather than total SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is an example plot which shows the error over time. Notice the rapid decrease in the beginning and the slow decrease of the error in the final iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran the algorithm with different inial settings. See the two tables below for the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-time run with different initial parameter settings.\n",
    "\n",
    "| Learning rate $\\eta$ | Regularization factor $\\lambda$ | Factor $k$ | Iterations | RMSE |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 0.001 | 0.01 | 10 | 100 | 0.9286 |\n",
    "| 0.01 | 0.1 | 10 | 100 | 0.8846 |\n",
    "| 0.03 | 0.3 | 10 | 100 | 0.9926 |\n",
    "\n",
    "5-fold cross validation run with the same initial settings.\n",
    "\n",
    "| Learning rate $\\eta$ | Regularization factor $\\lambda$ | Factor $k$ | Iterations | RMSE |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 0.005 | 0.05 | 12 | 100 | 0.8884 |\n",
    "| 0.005 | 0.05 | 12 | 100 | 0.8808 |\n",
    "| 0.005 | 0.05 | 12 | 100 | 0.8848 |\n",
    "| 0.005 | 0.05 | 12 | 100 | 0.8846 |\n",
    "| 0.005 | 0.05 | 12 | 100 | 0.8853 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "\n",
    "- We played a bit around with the $\\eta$ and $\\lambda$ values as you can see in the first table. The slides instructed $\\eta = 0.001$ and $\\lambda = 0.01$ as example parameter values. However, if we make both these values 10 times as large, we obtain a lower error after 100 iterations. This could mean these values are just better for our case, or that with lower parameter values, more iterations are needed to obtain the same accurate results.\n",
    "\n",
    "- One odd thing that occurs, is that the root mean squared error on the test set always decreases. This is peculiar, because if you keep training your data on the training set and test it simultaneously in the test set, you would expect there to be a point in time where an increase in accuracy on the training set won't give improvement on the test set. Unless we give the learning rate and regularization factor some absurd high values, the loop never terminates because of increasement in the error. We don't know exactly what causes this behaviour. However, if you take a look at the graph, the RMSE over time behaves as expected. To be more clear, the error starts at a relatively high value, which makes sense because the matrices $U$ and $M$ are randomly initialized from a gaussian distribution. The algorithm then quickly decreases the error, and in the end the error does not change much anymore. This curve is what you would expect, and since the final RMSE we obtained after 100 iterations looks really well, we'd argue the odd behaviour is not a large concern.\n",
    "\n",
    "- In the second table, where we tested the 5-fold cross validation, you can see that the RMSE for all the 5 cases are really close to each other. This makes sense, since each test set contains approximately $2 \\cdot 10^5$ elements and they are all randomly distributed. We also changed the factor $k$ to a larger number, to see the effect of this. A larger $k$ factor means $\\hat{x}_{ij}$ can be approximated more accurate, but it also means computations take longer. This is a trade-of which needs to be considered.\n",
    "\n",
    "- We think it is possible to obtain a lower RMSE using this method. For example, the number of iterations can be larger, the factor $k$ can be larger, and the parameter values $\\eta$ and $\\lambda$ can be tweaked more carefully. However, this all takes a lot of time, and since a single run already takes an hour, we haven't optimized the parameter values 100 percent. Also, the result $ \\text{RMSE} = 0.89 $ on the test set is already a large improvement compared to the naive models, so we were happy with that result.\n",
    "\n",
    "- The naive approaches were able to get fairly low RMSE values even though they were extremely simple methods of prediction. Due to their simplicity, their computation times were extremely short, indicating that these approaches are good starting points for handling data such as these. However, when compared to the Matrix Factorization approach these naive approaches score much worse. The Matrix Factorization, though much more computationally expensive, was able to acquire an average of Root Mean Square errors of $~0.82 $ on the training sets and $~0.89 $ on the test sets, this is a $~10\\%$ improvement of the best naive method (the Regression Model) and a staggering $~29\\%$ improvement of the global mean approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "In conclusion, the naive methods, though true to their names, are fast and deliver relatively good RMSE values. However, when trading simplicity and short computation times for complexity and long computation times respectively, we were able to make a large improvement in the RMSE using the Matrix Factorization technique with a gradient descent algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
