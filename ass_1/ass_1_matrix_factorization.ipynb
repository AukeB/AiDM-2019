{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AiDM 2019: Assignment 1 - Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auke Bruinsma, s1594443 and Simon van Wageningen, s2317079"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As instructed, we have divided the first assignment of AiDM into two parts: The first on the naive models and this part on the matrix factorization. The structure of this part will be as follows: Before each cell of code we'll provide background info in markdown cells if necessary. If a cells produces relevant output we'll write this down. At the end there will be a short conclusion/discussion section where we compare our results of the naive models and matrix factorization with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we import the three datasets using pandas. We have given each columns the names that are found in the readme file so that each column can be accesed with, for example, ratings['UserID']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/auke/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/auke/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/auke/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Import datasets and infer a header with the correct column labels.\n",
    "ratings = pd.read_csv(filepath_or_buffer='data/ml-1m/ratings.dat',sep='::',header=None,names=['UserID','MovieID','Rating','Timestamp'])\n",
    "users = pd.read_csv(filepath_or_buffer='data/ml-1m/users.dat',sep='::',header=None,names=['UserID','Gender','Age','Occupation','Zip-code'])\n",
    "movies = pd.read_csv(filepath_or_buffer='data/ml-1m/movies.dat',sep='::',header=None,names=['MovieID','Title','Genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the array $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported all necessary packages and datasets, we can start with the assignment. After a quick look at the data, we noticed the following things:\n",
    "\n",
    "- There are approximately 6000 users.\n",
    "- There are approximately 4000 movies.\n",
    "- Not every users has rated each movie.\n",
    "- Sometimes the ['MovieID'] column skips a number. This may mean that a movie is deleted from the database, or that no one has rated that movie. \n",
    "\n",
    "In order to complete the matrix factorization, we will create a matrix called $X$. This matrix has approximately the size $(6000,4000)$, where $X_{i,j}$ denotes how the $i_{th}$ user will rate the $j_{th}$ movie. Because of the last two points in the previous enumeration, there are a lot of empty elements in this matrix. Approximately 4.2 percent of the matrix $X$ has elements that are not equal to zero, which means 4.2 percent has been rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array X with at X[i][j] the ratings for how the ith user would rate the jth movies\n",
    "X = np.zeros((users['UserID'][len(users)-1]+1,movies['MovieID'][len(movies)-1]+1))\n",
    "\n",
    "# Fill array.\n",
    "for k in range(len(ratings)):\n",
    "    X[ratings['UserID'][k]][ratings['MovieID'][k]] = ratings['Rating'][k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we compute the percentage filled of the matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage filled: 4.188467095557036 %\n"
     ]
    }
   ],
   "source": [
    "# To get a better ovewview, here we print the number of matrix elements that is known.\n",
    "print('Percentage filled: {0} %'.format(100*len(ratings)/(len(X)*len(X[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact shape of the matrix $X$ is (6041,3953)$ and it also printed for a quick overview. You can see that that most elements are zero and only two elements have a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X: (6041, 3953)\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 3. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Shape X: {0}\\n'.format(X.shape))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the imported data in a matrix $X$. This matrix will form the basis of the computations that are needed to perform the matrix factorization. However, first we need to set up the N-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. N-fold cross-validation:\n",
    "\n",
    "1. Split your data in $N$ parts (equal size);\n",
    "2. Develop $N$ models on all combinations of $(N-1)$ parts;\n",
    "3. Test each model on the remaining parts (test sets);\n",
    "4. Average the errors over these $N$ test sets;\n",
    "5. The average error is a realistic estimator of the error made by your model on the fresh data.\n",
    "\n",
    "#### In practice:\n",
    "- $N=5$ (5-fold cross-validation) or $(N=10)$ (10-fold cross-validation)\n",
    "- Errors also measured on the training sets/folds\n",
    "- Standard deviation of errors says something about 'model stability'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text in the previous cell is taken from the slides. The idea of N-fold cross validation is to create your own training and testing set so that you can test the accuracy of your model. You divide all your data in $N$ parts, in our case 5 parts. Then 4/5 is used as a training set and 1/5 as a testing set. Yobu repeat this process for each one-fifth of the data, so that every one-fifth is used for testing, and each 4/5 is used for the training set. This will give an accurate outcome of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The splitting of the data in 5 parts is done in the following way: All the indices of the elements of the matrix $X$ which are not equal to zero, are stored in an list called non_zero_indices. Each element of this array contains the $i$-coordinate, $j$-coordinate, and also the rating. This means the size of this array is $(1000209,3)$, since there are $1000209$ ratings present in the matrix $x$. Next, the non_zero_indices array is random shuffled, to make the training set a bit more valid. The array is then splitted into 5 parts, and this array is returned by the function k_fold_cross_validation. The size of this list is $(n=5,~10^6/(n=5),3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array where all the indices will be stored which are not zero.\n",
    "non_zero_indices = []\n",
    "for i in range(len(X)):\n",
    "    for j in range(len(X[i])):\n",
    "        if X[i][j] != 0:\n",
    "            non_zero_indices.append((i,j,X[i][j])) # Has length 1.000.209."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above coding cell creates the array with the indices of the elements that have a rating. The code cell below is the function that randomly shuffles the data and splits it into 5 parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(data,k):\n",
    "    np.random.shuffle(data)\n",
    "    splitted_data = []\n",
    "    for i in range(k):\n",
    "        splitted_data.append(data[int(len(data)/k*i):int(len(data)/k*(i+1))])\n",
    "        print('Size set {0}: {1}'.format(i+1,np.shape(splitted_data[i])))\n",
    "    return splitted_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size set 1: (200041, 3)\n",
      "Size set 2: (200042, 3)\n",
      "Size set 3: (200042, 3)\n",
      "Size set 4: (200042, 3)\n",
      "Size set 5: (200042, 3)\n"
     ]
    }
   ],
   "source": [
    "folded_data = k_fold_cross_validation(non_zero_indices,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is some output that displays the size of each of the 5 sets. Each set contains approximately $2*10^5$ datapoints/ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have set up our data in 5 different parts. Next is the actual process called matrix factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Matrix factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following equations are taken from the gravity-tikk paper page 24.\n",
    "\n",
    "The matrix $X$ can be approximated as the product of two matrices:\n",
    "\n",
    "$$X \\approx UM $$\n",
    "\n",
    "$X$ has shape $(i,j)$ where $i$ denotes the $i$th user and $j$ denotes the $j$th movie. The actual element $(i,j)$ contains the rating the user has given the movie. The matrices $U$ and $M$ have shapes $(i,k)$ and $(k,j)$, respectively. $k$ is a factor which can be chosen. In the code this will simply be called $k$ and experimentation will be done with this value. Now, instead of having a single matrix with approximate size $(6000,4000)$, you have two matrices with sizes $(6000,k)$ and $(k,4000)$, which is much less data. The key idea is that the product of the matrices $U$ and $M$ will give accurate predictions of what rating a certain user will give to movie he hasn't rated yet, based on his/hers known ratings.\n",
    "\n",
    "How we do obtain the matrix elements of $U$ and $M$? We initialise the matrices with random weight produced by numpy.random.randn, which all values obtained from a gaussian distribution. The elements of $U$ and $M$ are then constantly updated over several iterations. They are computed with the following equations.\n",
    "\n",
    "$$ \\hat{x}_{ij} = \\sum_{k=1}^{K} = u_{ik}m_{kj} $$\n",
    "\n",
    "$ \\hat{x}_{ij} $ denotes the predicted values of what user $i$ will rate movie $j$. Next the error of the predicted value compared to the known value is computed. This is done only for values which are known, so for the total $1000209$ ratings given by the $6041$ users.\n",
    "\n",
    "$$ e_{ij} = x_{ij}-\\hat{x}_{ij} $$\n",
    "\n",
    "The total error of all these ratings is just the sum of the errors:\n",
    "\n",
    "$$ SE = \\sum_{ij} e^2_{ij} $$\n",
    "\n",
    "What you want, is to minimize the total error over time. The new values for the elements in the matrices $U$ and $M$ is computed with the two following algorithms:\n",
    "\n",
    "$$ u`_{ik}  = u_{ik} + \\eta \\cdot (2 e_{ij} \\cdot m_{kj} - \\lambda \\cdot u_{ik} ) $$\n",
    "$$ m`_{kj}  = m_{kj} + \\eta \\cdot (2 e_{ij} \\cdot u_{ik} - \\lambda \\cdot m_{kj} ) $$\n",
    "\n",
    "$ u`_{ik} $ is the updated parameter value. $\\eta$ is the learning rate, so it specifies how fast the algorithm learns. $\\lambda$ is the regularization factor to prevent large weights.\n",
    "\n",
    "After these computations are performed on the training set. The new matrices $U$ and $M$ are computed and the equations that compute the predicted matrix values $\\hat{x}_{ij}$ and the (total) error are computed on the test set. From this error the RMSE can be computed. This is just the square root of the mean of the total error. This value usually starts out high, around 3 are 4, then rapidly decreases in the first few iterations and then slowly drops to 0.9 or 0.8, depending on the initial parameter values for the learning rate and regularization value. The iteration process will be stopped of the error increases. That means no further improvement can be obtained using the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_fac(indices,X,test_set):\n",
    "    # Initial parameters. Set eta and lambda to some small positive values.\n",
    "    eta = 0.005 # Learning rate (eq. 6 gravity-tikk).\n",
    "    lamda = 0.05 # The regularization factor lambda (eq. 6 gravity-tikk).\n",
    "    k = 12 # The parameter that sets the shape of the matrices U and M.\n",
    "    n_iter = 100 # Number of maximum iterations.\n",
    "\n",
    "    # Initialise the two matrices (eq. 1 gravity-tikk)\n",
    "    U = np.random.randn(users['UserID'][len(users)-1]+1,k) # Initialise the weights of U ...\n",
    "    M = np.random.randn(k,movies['MovieID'][len(movies)-1]+1) # ... and M randomly.\n",
    "    \n",
    "    prev_RMSE = 10e10+1; RMSE = 10e10 # Set some initial values for the RMSE.\n",
    "    prev_RMSE_test = 10e10+1; RMSE_test = 10e10\n",
    "    \n",
    "    total_SE_test = []\n",
    "    \n",
    "    for n in range(n_iter):\n",
    "        if RMSE_test < prev_RMSE_test: # Only continue the loop if there is improvement.\n",
    "            prev_RMSE_test = RMSE_test\n",
    "            SE_test = 0; SE = 0 # The total squared error (which is equivalent to minimize RMSE).\n",
    "            for i in range(len(indices)): # Loop until the terminal condition is met.\n",
    "                if i != test_set: # Don't use the testing set for training.\n",
    "                    for j in range(len(indices[i])):\n",
    "                        x_hat_ij = np.dot(U[indices[i][j][0],:],M[:,indices[i][j][1]]) # Eq. 3 gravity-tikk\n",
    "                        e_ij = X[indices[i][j][0]][indices[i][j][1]]-x_hat_ij # Eq. 4 gravity-tikk\n",
    "                        SE += e_ij**2; # Total error.\n",
    "                        temp = U[indices[i][j][0],:]+eta*(2*e_ij*M[:,indices[i][j][1]]-lamda*U[indices[i][j][0],:])\n",
    "                        M[:,indices[i][j][1]] += eta*(2*e_ij*U[indices[i][j][0],:]-lamda*M[:,indices[i][j][1]])\n",
    "                        U[indices[i][j][0],:] = temp # Update factorised matrices.\n",
    "            X_pred = np.dot(U,M)\n",
    "            for j in range(len(indices[test_set])):\n",
    "                SE_test += (X[indices[test_set][j][0]][indices[test_set][j][1]]-X_pred[indices[test_set][j][0]][indices[test_set][j][1]])**2  \n",
    "                RMSE_test = (SE_test/len(indices[test_set]))**0.5\n",
    "            RMSE = np.sqrt(SE/800168) # Compute the root mean squared error. (Use a fixed number for efficiency.)\n",
    "            total_SE_test.append(SE_test) # For statistics.\n",
    "            sys.stdout.write('\\rIterations: {0}\\n'.format(n)) # Overview of the process.\n",
    "            sys.stdout.write('\\rSE_train: {0}. RMSE_train: {1}\\n'.format(SE,RMSE)) # Overview of the process.\n",
    "            sys.stdout.write('\\rSE_test:  {0}. RMSE_test:  {1}\\n\\n'.format(SE_test,RMSE_test)) # Overview of the process.        \n",
    "        else:\n",
    "            print('\\nError increased. Process terminated.\\n')\n",
    "            break;\n",
    "            \n",
    "    return U,M,total_SE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\n",
      "SE_train: 14064515.323242577. RMSE_train: 4.19248768560201\n",
      "SE_test:  2899222.06207733. RMSE_test:  3.806985581381573\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 7620082.536808458. RMSE_train: 3.085952578915223\n",
      "SE_test:  1107361.1546118236. RMSE_test:  2.3528006631485407\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 2912483.3763803593. RMSE_train: 1.9078364327441928\n",
      "SE_test:  562710.1741828651. RMSE_test:  1.677192359629935\n",
      "\n",
      "Iterations: 3\n",
      "SE_train: 1693423.4522644007. RMSE_train: 1.4547628277505065\n",
      "SE_test:  393731.3231178715. RMSE_test:  1.402944447830704\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 1253417.0734061184. RMSE_train: 1.2515759620798044\n",
      "SE_test:  318899.61216077214. RMSE_test:  1.2626049483890212\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 1043114.7802550715. RMSE_train: 1.14176167179436\n",
      "SE_test:  278771.76077781897. RMSE_test:  1.1804969806819532\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 925903.1308480541. RMSE_train: 1.075702521619204\n",
      "SE_test:  254630.56191044566. RMSE_test:  1.128225095767485\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 853834.196942427. RMSE_train: 1.0329901556932013\n",
      "SE_test:  238921.09813286655. RMSE_test:  1.0928680829504323\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 806268.8210991183. RMSE_train: 1.003804973709832\n",
      "SE_test:  228085.56161533244. RMSE_test:  1.0677987021403716\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 773107.7045968845. RMSE_train: 0.982945437235589\n",
      "SE_test:  220264.5227110184. RMSE_test:  1.0493316390412089\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 748947.4014533858. RMSE_train: 0.967464570101101\n",
      "SE_test:  214408.96910576112. RMSE_test:  1.0352898731171492\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 730694.3597577178. RMSE_train: 0.9556025233844774\n",
      "SE_test:  209890.79546450585. RMSE_test:  1.0243236223730476\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 716478.6349020593. RMSE_train: 0.9462611993913228\n",
      "SE_test:  206315.34006404234. RMSE_test:  1.0155615542347847\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 705117.7475300533. RMSE_train: 0.9387289970301839\n",
      "SE_test:  203424.463197524. RMSE_test:  1.0084214637980724\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 695834.7028317953. RMSE_train: 0.9325292275741739\n",
      "SE_test:  201043.4593508132. RMSE_test:  1.002502503460131\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 688101.7310752941. RMSE_train: 0.9273330443068198\n",
      "SE_test:  199050.5518586828. RMSE_test:  0.9975213152081932\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 681549.7879972634. RMSE_train: 0.9229075607772286\n",
      "SE_test:  197358.63790238556. RMSE_test:  0.9932728418564367\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 675914.1105838894. RMSE_train: 0.9190839178376347\n",
      "SE_test:  195903.9763878207. RMSE_test:  0.9896055383430269\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 671000.3601086461. RMSE_train: 0.9157370526097587\n",
      "SE_test:  194638.96204176053. RMSE_test:  0.9864052646670329\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 666662.9445963213. RMSE_train: 0.9127725447582898\n",
      "SE_test:  193527.38498493028. RMSE_test:  0.9835845667819565\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 662790.7761030503. RMSE_train: 0.9101178627401818\n",
      "SE_test:  192541.24668882808. RMSE_test:  0.9810753891091762\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 659297.6952630933. RMSE_train: 0.9077164148400176\n",
      "SE_test:  191658.57604837194. RMSE_test:  0.9788240242584028\n",
      "\n",
      "Iterations: 22\n",
      "SE_train: 656115.9003207331. RMSE_train: 0.9055234293699294\n",
      "SE_test:  190861.9031649354. RMSE_test:  0.976787552372864\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 653191.354565852. RMSE_train: 0.9035030528317848\n",
      "SE_test:  190137.17473858033. RMSE_test:  0.9749312914422122\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 650480.5232894606. RMSE_train: 0.9016262744755571\n",
      "SE_test:  189472.97152709507. RMSE_test:  0.9732269456013372\n",
      "\n",
      "Iterations: 25\n",
      "SE_train: 647948.0204407967. RMSE_train: 0.8998694210307769\n",
      "SE_test:  188859.93583319362. RMSE_test:  0.9716512426831962\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 645564.8874365884. RMSE_train: 0.8982130505019821\n",
      "SE_test:  188290.34709097503. RMSE_test:  0.9701849191806204\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 643307.3167917919. RMSE_train: 0.8966411284755749\n",
      "SE_test:  187757.80309200098. RMSE_test:  0.9688119544867094\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 641155.6916288557. RMSE_train: 0.8951404060276265\n",
      "SE_test:  187256.97722960924. RMSE_test:  0.9675189853877254\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 639093.8507156012. RMSE_train: 0.8936999420842212\n",
      "SE_test:  186783.43078044703. RMSE_test:  0.9662948515466226\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 637108.5148126081. RMSE_train: 0.8923107293111828\n",
      "SE_test:  186333.46519073696. RMSE_test:  0.9651302364433304\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 635188.8283050361. RMSE_train: 0.8909653940088232\n",
      "SE_test:  185904.00353305586. RMSE_test:  0.9640173780159413\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 633325.9831670872. RMSE_train: 0.8896579487606697\n",
      "SE_test:  185492.4933404116. RMSE_test:  0.9629498303987626\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 631512.9019980637. RMSE_train: 0.8883835827871003\n",
      "SE_test:  185096.82527590162. RMSE_test:  0.9619222635011101\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 629743.9642137303. RMSE_train: 0.8871384797109774\n",
      "SE_test:  184715.26378460086. RMSE_test:  0.9609302912193812\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 628014.7650710569. RMSE_train: 0.8859196561060351\n",
      "SE_test:  184346.38713371384. RMSE_test:  0.9599703221191802\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 626321.9013803109. RMSE_train: 0.8847248169600659\n",
      "SE_test:  183989.03516128586. RMSE_test:  0.9590394286462686\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 624662.7806979268. RMSE_train: 0.8835522261416023\n",
      "SE_test:  183642.26368044. RMSE_test:  0.9581352324499133\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 623035.4526523326. RMSE_train: 0.8824005911980753\n",
      "SE_test:  183305.3048747964. RMSE_test:  0.9572558043415659\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 621438.461987107. RMSE_train: 0.8812689624270305\n",
      "SE_test:  182977.53322294378. RMSE_test:  0.9563995778875267\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 619870.7231185843. RMSE_train: 0.8801566462832687\n",
      "SE_test:  182658.4365585564. RMSE_test:  0.9555652757758346\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 618331.4157235443. RMSE_train: 0.8790631329638195\n",
      "SE_test:  182347.59186165803. RMSE_test:  0.9547518480393565\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 616819.9003342924. RMSE_train: 0.87798803761161\n",
      "SE_test:  182044.64533041455. RMSE_test:  0.9539584210723757\n",
      "\n",
      "Iterations: 43\n",
      "SE_train: 615335.6523287579. RMSE_train: 0.8769310541402141\n",
      "SE_test:  181749.2962377999. RMSE_test:  0.9531842562393691\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 613878.2122123821. RMSE_train: 0.8758919203119203\n",
      "SE_test:  181461.2840532901. RMSE_test:  0.9524287167930381\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 612447.1497831095. RMSE_train: 0.8748703924617233\n",
      "SE_test:  181180.3783145938. RMSE_test:  0.9516912418152857\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 611042.0396780615. RMSE_train: 0.8738662281715559\n",
      "SE_test:  180906.3707668399. RMSE_test:  0.9509713259658903\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 609662.4458907408. RMSE_train: 0.872879175242465\n",
      "SE_test:  180639.06933758044. RMSE_test:  0.9502685039455091\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 608307.9130836299. RMSE_train: 0.8719089654621555\n",
      "SE_test:  180378.2935779551. RMSE_test:  0.9495823387327077\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 606977.9628317194. RMSE_train: 0.8709553118714192\n",
      "SE_test:  180123.8712623229. RMSE_test:  0.9489124128097081\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 605672.093277568. RMSE_train: 0.8700179084669113\n",
      "SE_test:  179875.63589749648. RMSE_test:  0.9482583217400777\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 604389.7810098802. RMSE_train: 0.8690964315050584\n",
      "SE_test:  179633.42494223564. RMSE_test:  0.9476196695870921\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 603130.4842740739. RMSE_train: 0.8681905417770098\n",
      "SE_test:  179397.0785791441. RMSE_test:  0.9469960657670452\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 601893.6468710529. RMSE_train: 0.8672998873970489\n",
      "SE_test:  179166.4389135771. RMSE_test:  0.9463871230144834\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 600678.7022969961. RMSE_train: 0.8664241067845201\n",
      "SE_test:  178941.3494997644. RMSE_test:  0.945792456201639\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 599485.0778291725. RMSE_train: 0.865562831626458\n",
      "SE_test:  178721.6551139885. RMSE_test:  0.9452116818044736\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 598312.1983711732. RMSE_train: 0.8647156896847248\n",
      "SE_test:  178507.20171069502. RMSE_test:  0.9446444178487796\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 597159.4899504839. RMSE_train: 0.8638823073680224\n",
      "SE_test:  178297.83650939018. RMSE_test:  0.9440902842004482\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 596026.3828169199. RMSE_train: 0.8630623120289268\n",
      "SE_test:  178093.40817094338. RMSE_test:  0.9435489030916994\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 594912.3141231947. RMSE_train: 0.862255333969696\n",
      "SE_test:  177893.7670302265. RMSE_test:  0.9430198997964958\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 593816.7301963238. RMSE_train: 0.8614610081605567\n",
      "SE_test:  177698.7653590978. RMSE_test:  0.9425029033866665\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 61\n",
      "SE_train: 592739.0884203017. RMSE_train: 0.86067897568289\n",
      "SE_test:  177508.2576400182. RMSE_test:  0.9419975475165994\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 591678.8587589926. RMSE_train: 0.859908884916167\n",
      "SE_test:  177322.10083544877. RMSE_test:  0.9415034711970303\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 590635.5249540439. RMSE_train: 0.8591503924920257\n",
      "SE_test:  177140.15464233307. RMSE_test:  0.9410203195293411\n",
      "\n",
      "Iterations: 64\n",
      "SE_train: 589608.5854315872. RMSE_train: 0.8584031640384123\n",
      "SE_test:  176962.28172442308. RMSE_test:  0.9405477443808613\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 588597.5539537853. RMSE_train: 0.8576668747386403\n",
      "SE_test:  176788.34791787594. RMSE_test:  0.940085404988718\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 587601.9600471273. RMSE_train: 0.856941209727455\n",
      "SE_test:  176618.2224075191. RMSE_test:  0.939632968484996\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 586621.3492397607. RMSE_train: 0.8562258643466908\n",
      "SE_test:  176451.7778730104. RMSE_test:  0.9391901103408525\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 585655.2831361599. RMSE_train: 0.8555205442804081\n",
      "SE_test:  176288.89060502534. RMSE_test:  0.9387565147296543\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 584703.3393549396. RMSE_train: 0.8548249655877501\n",
      "SE_test:  176129.44059264433. RMSE_test:  0.9383318748120132\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 583765.1113538218. RMSE_train: 0.854138854650602\n",
      "SE_test:  175973.31158356467. RMSE_test:  0.9379158929468375\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 582840.20816192. RMSE_train: 0.8534619480504554\n",
      "SE_test:  175820.39111910108. RMSE_test:  0.9375082808334527\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 581928.2540378153. RMSE_train: 0.8527939923877537\n",
      "SE_test:  175670.5705462975. RMSE_test:  0.9371087595908442\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 581028.8880697404. RMSE_train: 0.8521347440555102\n",
      "SE_test:  175523.74500932737. RMSE_test:  0.9367170597797234\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 580141.7637311168. RMSE_train: 0.8514839689768192\n",
      "SE_test:  175379.81342251875. RMSE_test:  0.936332921373571\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 579266.5484033127. RMSE_train: 0.8508414423149293\n",
      "SE_test:  175238.67842722486. RMSE_test:  0.9359560936845365\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 578402.9228762288. RMSE_train: 0.8502069481636796\n",
      "SE_test:  175100.2463346949. RMSE_test:  0.9355863352499222\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 577550.5808345792. RMSE_train: 0.8495802792241274\n",
      "SE_test:  174964.4270568838. RMSE_test:  0.935223413684426\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 576709.2283369458. RMSE_train: 0.8489612364726468\n",
      "SE_test:  174831.13402713393. RMSE_test:  0.9348671055033193\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 575878.5832942446. RMSE_train: 0.8483496288254818\n",
      "SE_test:  174700.28411248414. RMSE_test:  0.9345171959212836\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 575058.3749513179. RMSE_train: 0.847745272802603\n",
      "SE_test:  174571.79751901785. RMSE_test:  0.9341734786307161\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 574248.343376327. RMSE_train: 0.8471479921944371\n",
      "SE_test:  174445.59769197597. RMSE_test:  0.9338357555641752\n",
      "\n",
      "Iterations: 82\n",
      "SE_train: 573448.238960679. RMSE_train: 0.8465576177336182\n",
      "SE_test:  174321.6112116105. RMSE_test:  0.9335038366436325\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 572657.8219321113. RMSE_train: 0.8459739867738348\n",
      "SE_test:  174199.76768626747. RMSE_test:  0.9331775395205796\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 571876.861882478. RMSE_train: 0.8453969429770529\n",
      "SE_test:  174079.99964348655. RMSE_test:  0.9328566893091677\n",
      "\n",
      "Iterations: 85\n",
      "SE_train: 571105.137311978. RMSE_train: 0.8448263360105371\n",
      "SE_test:  173962.24242022002. RMSE_test:  0.9325411183154035\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 570342.4351906622. RMSE_train: 0.8442620212544302\n",
      "SE_test:  173846.43405289963. RMSE_test:  0.9322306657644281\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 569588.5505376842. RMSE_train: 0.8437038595203685\n",
      "SE_test:  173732.51516806486. RMSE_test:  0.9319251775278633\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 568843.2860189585. RMSE_train: 0.8431517167817549\n",
      "SE_test:  173620.42887429267. RMSE_test:  0.9316245058532877\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 568106.4515631457. RMSE_train: 0.8426054639157581\n",
      "SE_test:  173510.1206557074. RMSE_test:  0.9313285090966594\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 567377.863996024. RMSE_train: 0.8420649764572026\n",
      "SE_test:  173401.53826781426. RMSE_test:  0.9310370514597565\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 566657.3466932201. RMSE_train: 0.841530134364448\n",
      "SE_test:  173294.63163580562. RMSE_test:  0.9307500027331038\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 565944.7292503534. RMSE_train: 0.8410008217966655\n",
      "SE_test:  173189.35275572073. RMSE_test:  0.9304672380454795\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 565239.8471712196. RMSE_train: 0.8404769269030808\n",
      "SE_test:  173085.65559871492. RMSE_test:  0.9301886376207543\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 564542.5415724629. RMSE_train: 0.8399583416231364\n",
      "SE_test:  172983.49601857626. RMSE_test:  0.9299140865424985\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 563852.6589049876. RMSE_train: 0.8394449614978482\n",
      "SE_test:  172882.8316626697. RMSE_test:  0.9296434745269037\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 563170.0506910498. RMSE_train: 0.8389366854916627\n",
      "SE_test:  172783.6218863583. RMSE_test:  0.9293766957042098\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 562494.5732766443. RMSE_train: 0.8384334158246101\n",
      "SE_test:  172685.82767097186. RMSE_test:  0.9291136484088849\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 561826.0875984468. RMSE_train: 0.8379350578142822\n",
      "SE_test:  172589.41154528238. RMSE_test:  0.9288542349785004\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 561164.4589646354. RMSE_train: 0.8374415197272057\n",
      "SE_test:  172494.3375106035. RMSE_test:  0.9285983615616673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "U_0,M_0,SE_0 = mat_fac(folded_data,X,0) # Done with 0.001,0.01,10,100. Gives 0.928598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\n",
      "SE_train: 3563131.281638583. RMSE_train: 2.110208277981861\n",
      "SE_test:  218363.4999660699. RMSE_test:  1.044793627046562\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 758722.2108931269. RMSE_train: 0.9737574856461078\n",
      "SE_test:  194973.27318762627. RMSE_test:  0.9872520242032813\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 712640.6723028921. RMSE_train: 0.9437233765665682\n",
      "SE_test:  188592.10549669852. RMSE_test:  0.9709620281942815\n",
      "\n",
      "Iterations: 3\n",
      "SE_train: 693177.3835320486. RMSE_train: 0.930746908968955\n",
      "SE_test:  184516.1861338203. RMSE_test:  0.9604123282954209\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 677328.8656294869. RMSE_train: 0.9200452817875571\n",
      "SE_test:  180999.01673359226. RMSE_test:  0.9512148010309935\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 662990.4625445812. RMSE_train: 0.9102549531444387\n",
      "SE_test:  178020.4685762454. RMSE_test:  0.9433556642644494\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 650482.453990434. RMSE_train: 0.9016276125397816\n",
      "SE_test:  175542.38310307692. RMSE_test:  0.9367667913899314\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 639624.8201966492. RMSE_train: 0.8940711151706139\n",
      "SE_test:  173458.641885889. RMSE_test:  0.9311903407800356\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 630178.0385136841. RMSE_train: 0.8874441735333362\n",
      "SE_test:  171697.29805732178. RMSE_test:  0.9264505041428821\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 621956.3304455386. RMSE_train: 0.8816360835391922\n",
      "SE_test:  170203.39982603633. RMSE_test:  0.9224112837568821\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 614759.0902048044. RMSE_train: 0.8765201209192556\n",
      "SE_test:  168924.8480768174. RMSE_test:  0.9189402199832516\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 608381.329086292. RMSE_train: 0.871961578734384\n",
      "SE_test:  167815.3036420367. RMSE_test:  0.9159173231132349\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 602650.1058470829. RMSE_train: 0.8678447268205188\n",
      "SE_test:  166838.19447222416. RMSE_test:  0.9132469536009836\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 597440.5469695863. RMSE_train: 0.8640855793816946\n",
      "SE_test:  165967.1388188249. RMSE_test:  0.910859820523187\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 592671.6781240032. RMSE_train: 0.8606300331755006\n",
      "SE_test:  165184.04961494313. RMSE_test:  0.9087084070955022\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 588293.3865364819. RMSE_train: 0.8574452394057014\n",
      "SE_test:  164476.63705304553. RMSE_test:  0.906760514836094\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 584273.1808684089. RMSE_train: 0.8545104660428858\n",
      "SE_test:  163836.24976985765. RMSE_test:  0.9049935641275634\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 580586.5151173071. RMSE_train: 0.8518102910475592\n",
      "SE_test:  163256.28958930436. RMSE_test:  0.90339036111024\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 577211.0306534033. RMSE_train: 0.8493305023565827\n",
      "SE_test:  162731.16768273283. RMSE_test:  0.9019362910725278\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 574123.9206559601. RMSE_train: 0.8470562112001271\n",
      "SE_test:  162255.73675142045. RMSE_test:  0.9006177911378006\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 571301.4417403948. RMSE_train: 0.8449715184746859\n",
      "SE_test:  161825.08839534235. RMSE_test:  0.8994218172012696\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 568719.5684687311. RMSE_train: 0.8430600233929224\n",
      "SE_test:  161434.55956462788. RMSE_test:  0.8983358844630832\n",
      "\n",
      "Iterations: 22\n",
      "SE_train: 566354.9508434918. RMSE_train: 0.8413055637481129\n",
      "SE_test:  161079.8088668798. RMSE_test:  0.8973482999205314\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 564185.6865525083. RMSE_train: 0.8396928251105409\n",
      "SE_test:  160756.88180697622. RMSE_test:  0.8964483627087204\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 562191.7557731533. RMSE_train: 0.8382077012082775\n",
      "SE_test:  160462.23782034218. RMSE_test:  0.8956264561848104\n",
      "\n",
      "Iterations: 25\n",
      "SE_train: 560355.1597348423. RMSE_train: 0.8368374318362051\n",
      "SE_test:  160192.74206734227. RMSE_test:  0.8948740394210201\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 558659.8661827975. RMSE_train: 0.8355705926510837\n",
      "SE_test:  159945.63512520381. RMSE_test:  0.8941835745257816\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 557091.6567474833. RMSE_train: 0.8343970068724407\n",
      "SE_test:  159718.49336239713. RMSE_test:  0.8935484256100835\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 555637.9411131606. RMSE_train: 0.8333076275032044\n",
      "SE_test:  159509.18879556557. RMSE_test:  0.8929627543012705\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 554287.5740370691. RMSE_train: 0.8322944176232584\n",
      "SE_test:  159315.85305168308. RMSE_test:  0.892421425100507\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 553030.6907871063. RMSE_train: 0.8313502411180065\n",
      "SE_test:  159136.84693051685. RMSE_test:  0.8919199251145009\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 551858.5644014415. RMSE_train: 0.830468767048745\n",
      "SE_test:  158970.73516718316. RMSE_test:  0.8914542973306309\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 550763.4821619553. RMSE_train: 0.8296443862540378\n",
      "SE_test:  158816.2651130621. RMSE_test:  0.8910210840704038\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 549738.6365887567. RMSE_train: 0.8288721370885989\n",
      "SE_test:  158672.34787427165. RMSE_test:  0.890617276695765\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 548778.0263996675. RMSE_train: 0.8281476372076972\n",
      "SE_test:  158538.04068913424. RMSE_test:  0.8902402682758981\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 547876.3641001312. RMSE_train: 0.8274670191463411\n",
      "SE_test:  158412.52976797012. RMSE_test:  0.8898878071287689\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 547028.9884311192. RMSE_train: 0.8268268685632305\n",
      "SE_test:  158295.11329969825. RMSE_test:  0.8895579504800699\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 546231.7813476424. RMSE_train: 0.8262241650706267\n",
      "SE_test:  158185.1847385888. RMSE_test:  0.8892490186165157\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 545481.0902495809. RMSE_train: 0.8256562263370376\n",
      "SE_test:  158082.21675719827. RMSE_test:  0.8889595506681015\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 544773.6567196966. RMSE_train: 0.825120656533985\n",
      "SE_test:  157985.74636492957. RMSE_test:  0.8886882634673279\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 544106.5530517926. RMSE_train: 0.824615300204975\n",
      "SE_test:  157895.3616616274. RMSE_test:  0.8884340148448824\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 543477.127486681. RMSE_train: 0.8241382023455002\n",
      "SE_test:  157810.69056248665. RMSE_test:  0.8881957723428894\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 542882.9584920568. RMSE_train: 0.8236875750298815\n",
      "SE_test:  157731.39164713572. RMSE_test:  0.8879725878064908\n",
      "\n",
      "Iterations: 43\n",
      "SE_train: 542321.8177995392. RMSE_train: 0.8232617704360291\n",
      "SE_test:  157657.14710150048. RMSE_test:  0.8877635777912054\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 541791.6413912723. RMSE_train: 0.8228592597116586\n",
      "SE_test:  157587.65756978217. RMSE_test:  0.8875679092927039\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 541290.5072876749. RMSE_train: 0.8224786168550554\n",
      "SE_test:  157522.63863513435. RMSE_test:  0.8873847900227563\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 540816.6188431452. RMSE_train: 0.8221185066629639\n",
      "SE_test:  157461.81860160007. RMSE_test:  0.887213462321113\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 540368.2922792124. RMSE_train: 0.8217776758064436\n",
      "SE_test:  157404.93724919623. RMSE_test:  0.8870531997874954\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 539943.9473223697. RMSE_train: 0.8214549461930039\n",
      "SE_test:  157351.7452645205. RMSE_test:  0.8869033058008439\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 539542.1000108274. RMSE_train: 0.8211492099175979\n",
      "SE_test:  157302.00409751743. RMSE_test:  0.8867631132268056\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 539161.3569458394. RMSE_train: 0.8208594252617988\n",
      "SE_test:  157255.48604932835. RMSE_test:  0.8866319847659331\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 538800.4104587557. RMSE_train: 0.8205846133463848\n",
      "SE_test:  157211.974448731. RMSE_test:  0.8865093135423003\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 538458.0343282188. RMSE_train: 0.8203238551648546\n",
      "SE_test:  157171.26382065727. RMSE_test:  0.8863945236612832\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 538133.0798090124. RMSE_train: 0.820076288820847\n",
      "SE_test:  157133.1599875433. RMSE_test:  0.8862870705700086\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 537824.471826941. RMSE_train: 0.8198411068622816\n",
      "SE_test:  157097.48007279515. RMSE_test:  0.8861864411342816\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 537531.205259049. RMSE_train: 0.8196175536539082\n",
      "SE_test:  157064.05239591832. RMSE_test:  0.8860921534029097\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 537252.3412602816. RMSE_train: 0.8194049227613833\n",
      "SE_test:  157032.7162623535. RMSE_test:  0.8860037560684126\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 536987.0036263084. RMSE_train: 0.8192025543414932\n",
      "SE_test:  157003.32165950435. RMSE_test:  0.8859208276569538\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 536734.3751967833. RMSE_train: 0.8190098325440057\n",
      "SE_test:  156975.7288744935. RMSE_test:  0.885842975491783\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 536493.6943134081. RMSE_train: 0.8188261829381182\n",
      "SE_test:  156949.80805096912. RMSE_test:  0.8857698344795404\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 536264.2513510319. RMSE_train: 0.8186510699792497\n",
      "SE_test:  156925.4387018764. RMSE_test:  0.8857010657676281\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 61\n",
      "SE_train: 536045.3853405264. RMSE_train: 0.8184839945321495\n",
      "SE_test:  156902.5091938025. RMSE_test:  0.8856363553171648\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 535836.4807025524. RMSE_train: 0.8183244914664294\n",
      "SE_test:  156880.9162166919. RMSE_test:  0.8855754124309141\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 535636.9641080613. RMSE_train: 0.8181721273379988\n",
      "SE_test:  156860.56425032482. RMSE_test:  0.8855179682687631\n",
      "\n",
      "Iterations: 64\n",
      "SE_train: 535446.3014791866. RMSE_train: 0.8180264981680759\n",
      "SE_test:  156841.36503705816. RMSE_test:  0.8854637743779612\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 535263.995141225. RMSE_train: 0.8178872273290734\n",
      "SE_test:  156823.23706817388. RMSE_test:  0.8854126012592114\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 535089.5811328542. RMSE_train: 0.8177539635438281\n",
      "SE_test:  156806.10508948102. RMSE_test:  0.8853642369848796\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 534922.6266785109. RMSE_train: 0.8176263790020808\n",
      "SE_test:  156789.89962992843. RMSE_test:  0.8853184858802208\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 534762.7278247107. RMSE_train: 0.8175041675963741\n",
      "SE_test:  156774.55655622968. RMSE_test:  0.885275167276356\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 534609.5072389785. RMSE_train: 0.8173870432770723\n",
      "SE_test:  156760.0166547717. RMSE_test:  0.8852341143388198\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 534462.6121677273. RMSE_train: 0.8172747385243415\n",
      "SE_test:  156746.2252415896. RMSE_test:  0.8851951729740879\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 534321.7125488364. RMSE_train: 0.8171670029344072\n",
      "SE_test:  156733.13180034023. RMSE_test:  0.885158200814072\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 534186.4992716965. RMSE_train: 0.817063601915059\n",
      "SE_test:  156720.6896475531. RMSE_test:  0.885123066276697\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 534056.6825780368. RMSE_train: 0.8169643154857272\n",
      "SE_test:  156708.85562432057. RMSE_test:  0.885089647700326\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 533931.9905952082. RMSE_train: 0.8168689371761546\n",
      "SE_test:  156697.58981283335. RMSE_test:  0.8850578325476484\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 533812.167992895. RMSE_train: 0.8167772730170926\n",
      "SE_test:  156686.85527650817. RMSE_test:  0.885027516675589\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 533696.9747555766. RMSE_train: 0.8166891406174484\n",
      "SE_test:  156676.61782184424. RMSE_test:  0.8849986036660626\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 533586.1850609008. RMSE_train: 0.8166043683206148\n",
      "SE_test:  156666.84578056773. RMSE_test:  0.8849710042135772\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 533479.5862561906. RMSE_train: 0.8165227944342606\n",
      "SE_test:  156657.50981016833. RMSE_test:  0.8849446355643944\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 533376.9779243338. RMSE_train: 0.8164442665270819\n",
      "SE_test:  156648.58271143388. RMSE_test:  0.8849194210033631\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 533278.1710307647. RMSE_train: 0.8163686407863469\n",
      "SE_test:  156640.03926126764. RMSE_test:  0.8848952893836296\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 533182.9871453007. RMSE_train: 0.8162957814316092\n",
      "SE_test:  156631.85605954996. RMSE_test:  0.8848721746957646\n",
      "\n",
      "Iterations: 82\n",
      "SE_train: 533091.2577297139. RMSE_train: 0.8162255601777453\n",
      "SE_test:  156624.0113885571. RMSE_test:  0.8848500156721405\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 533002.8234864462. RMSE_train: 0.8161578557439144\n",
      "SE_test:  156616.48508384195. RMSE_test:  0.8848287554234959\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 532917.5337612638. RMSE_train: 0.8160925534030308\n",
      "SE_test:  156609.2584154824. RMSE_test:  0.8848083411046214\n",
      "\n",
      "Iterations: 85\n",
      "SE_train: 532835.2459949863. RMSE_train: 0.8160295445681088\n",
      "SE_test:  156602.31397865654. RMSE_test:  0.8847887236062468\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 532755.8252186467. RMSE_train: 0.8159687264112438\n",
      "SE_test:  156595.63559278645. RMSE_test:  0.88476985727101\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 532679.1435884434. RMSE_train: 0.8159100015125044\n",
      "SE_test:  156589.2082084243. RMSE_test:  0.8847516996311855\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 532605.0799558957. RMSE_train: 0.8158532775352881\n",
      "SE_test:  156583.01782116978. RMSE_test:  0.8847342111661815\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 532533.5194697387. RMSE_train: 0.8157984669255387\n",
      "SE_test:  156577.051392112. RMSE_test:  0.8847173550783848\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 532464.3532067263. RMSE_train: 0.8157454866327033\n",
      "SE_test:  156571.2967741815. RMSE_test:  0.8847010970856285\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 532397.4778279928. RMSE_train: 0.8156942578499068\n",
      "SE_test:  156565.74264399838. RMSE_test:  0.884685405229122\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 532332.7952590315. RMSE_train: 0.8156447057718931\n",
      "SE_test:  156560.37843877188. RMSE_test:  0.8846702496955952\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 532270.2123910366. RMSE_train: 0.815596759369039\n",
      "SE_test:  156555.19429790936. RMSE_test:  0.8846556026526986\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 532209.6408012165. RMSE_train: 0.8155503511756383\n",
      "SE_test:  156550.18100896155. RMSE_test:  0.88464143809661\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 532150.9964912527. RMSE_train: 0.8155054170918496\n",
      "SE_test:  156545.32995765697. RMSE_test:  0.8846277317111553\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 532094.1996416087. RMSE_train: 0.8154618961975718\n",
      "SE_test:  156540.63308169032. RMSE_test:  0.8846144607375022\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 532039.1743810156. RMSE_train: 0.8154197305777536\n",
      "SE_test:  156536.0828280501. RMSE_test:  0.8846016038538222\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 531985.8485695337. RMSE_train: 0.8153788651579279\n",
      "SE_test:  156531.67211365426. RMSE_test:  0.8845891410642747\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 531934.1535945975. RMSE_train: 0.815339247549535\n",
      "SE_test:  156527.39428908445. RMSE_test:  0.8845770535967195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "U_0,M_0,SE_0 = mat_fac(folded_data,X,0) # Done with 0.01,0.1,10,100. Gives 0.884577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(np.arange(0,len(SE_0)),SE_0,'.')\n",
    "plt.xlabel('Iterations'); plt.ylabel('Total error')\n",
    "plt.title('Total error over time')\n",
    "plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is an example plot which shows the error over time. Notice the rapid decrease in the beginning and the slow decrease of the error in the final iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\n",
      "SE_train: 2114250.6114910557. RMSE_train: 1.625502503874386\n",
      "SE_test:  215893.18295419298. RMSE_test:  1.0388670124773884\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 834314.6712030494. RMSE_train: 1.0211142822351282\n",
      "SE_test:  208344.55160086154. RMSE_test:  1.0205436044620255\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 812379.923566795. RMSE_train: 1.0076019548917114\n",
      "SE_test:  204544.26320673482. RMSE_test:  1.0111932066301381\n",
      "\n",
      "Iterations: 3\n",
      "SE_train: 801344.274462045. RMSE_train: 1.0007347472584023\n",
      "SE_test:  202665.59429341645. RMSE_test:  1.006538763192611\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 795298.3347571266. RMSE_train: 0.9969524544656834\n",
      "SE_test:  201481.58540320818. RMSE_test:  1.0035942659853352\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 791239.4717054728. RMSE_train: 0.9944051904925058\n",
      "SE_test:  200656.21063913417. RMSE_test:  1.0015365309033966\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 788395.4988091203. RMSE_train: 0.9926164733390939\n",
      "SE_test:  200088.1694431193. RMSE_test:  1.0001178924890939\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 786412.828230544. RMSE_train: 0.9913675631483384\n",
      "SE_test:  199694.11423085327. RMSE_test:  0.999132587117098\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 784985.6269515118. RMSE_train: 0.9904675755548803\n",
      "SE_test:  199406.6002402918. RMSE_test:  0.9984130664849779\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 783886.8835835872. RMSE_train: 0.989774154731894\n",
      "SE_test:  199182.2115702905. RMSE_test:  0.9978511602083634\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 782978.2679089843. RMSE_train: 0.989200356977048\n",
      "SE_test:  198996.28805873825. RMSE_test:  0.9973853372212547\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 782184.6392008077. RMSE_train: 0.9886989019120506\n",
      "SE_test:  198835.73195158865. RMSE_test:  0.9969828959939523\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 781468.4516005678. RMSE_train: 0.9882461596695271\n",
      "SE_test:  198693.67668255788. RMSE_test:  0.996626692466212\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 780811.341372039. RMSE_train: 0.9878305810062405\n",
      "SE_test:  198566.2619694587. RMSE_test:  0.9963070917864426\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 780203.4764113342. RMSE_train: 0.9874459909794037\n",
      "SE_test:  198450.97888373563. RMSE_test:  0.9960178331015402\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 779638.4635666871. RMSE_train: 0.9870883786825876\n",
      "SE_test:  198345.98465436295. RMSE_test:  0.995754317242186\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 779111.5423260876. RMSE_train: 0.986754758826759\n",
      "SE_test:  198249.87513939533. RMSE_test:  0.9955130392032421\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 778619.128783913. RMSE_train: 0.9864428855088131\n",
      "SE_test:  198161.59848083803. RMSE_test:  0.995291373616751\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 778158.6403946535. RMSE_train: 0.9861511429477746\n",
      "SE_test:  198080.3746940801. RMSE_test:  0.9950873744046033\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 777728.2209957654. RMSE_train: 0.9858783725439778\n",
      "SE_test:  198005.6006701772. RMSE_test:  0.9948995372436347\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 777326.3853384933. RMSE_train: 0.9856236484267642\n",
      "SE_test:  197936.76257148548. RMSE_test:  0.9947265801509123\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 776951.709063971. RMSE_train: 0.9853860813543112\n",
      "SE_test:  197873.37677485263. RMSE_test:  0.9945672954771289\n",
      "\n",
      "Iterations: 22\n",
      "SE_train: 776602.649684911. RMSE_train: 0.9851647053725734\n",
      "SE_test:  197814.96459998956. RMSE_test:  0.994420486624538\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 776277.5070870002. RMSE_train: 0.9849584528275561\n",
      "SE_test:  197761.0531143601. RMSE_test:  0.994284970236593\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 775974.4820960913. RMSE_train: 0.9847661915831474\n",
      "SE_test:  197711.1896280695. RMSE_test:  0.9941596127918935\n",
      "\n",
      "Iterations: 25\n",
      "SE_train: 775691.7787998375. RMSE_train: 0.9845867900591057\n",
      "SE_test:  197664.95911312508. RMSE_test:  0.9940433745608745\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 775427.7071026482. RMSE_train: 0.984419182483597\n",
      "SE_test:  197621.9978170932. RMSE_test:  0.9939353440010646\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 775180.7598433894. RMSE_train: 0.9842624180459424\n",
      "SE_test:  197582.00016182533. RMSE_test:  0.9938347552623471\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 774949.6543523009. RMSE_train: 0.9841156874911807\n",
      "SE_test:  197544.71866729215. RMSE_test:  0.9937409881354412\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 774733.3388776111. RMSE_train: 0.9839783274004399\n",
      "SE_test:  197509.95815171787. RMSE_test:  0.9936535535813061\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 774530.9704752762. RMSE_train: 0.983849806322795\n",
      "SE_test:  197477.56614431378. RMSE_test:  0.9935720697074469\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 774341.8739105054. RMSE_train: 0.9837296988110423\n",
      "SE_test:  197447.421577061. RMSE_test:  0.9934962333890978\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 774165.4917237669. RMSE_train: 0.983617653806622\n",
      "SE_test:  197419.42358126148. RMSE_test:  0.9934257921311439\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 774001.3344690885. RMSE_train: 0.9835133630988081\n",
      "SE_test:  197393.48174642556. RMSE_test:  0.9933605195910203\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 773848.9378368164. RMSE_train: 0.9834165341295136\n",
      "SE_test:  197369.50863713617. RMSE_test:  0.9933001967698867\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 773707.8305786481. RMSE_train: 0.983326869641765\n",
      "SE_test:  197347.41482790306. RMSE_test:  0.9932445995314765\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 773577.5144866763. RMSE_train: 0.9832440549758233\n",
      "SE_test:  197327.10629357616. RMSE_test:  0.9931934920441182\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 773457.4555831199. RMSE_train: 0.9831677524841321\n",
      "SE_test:  197308.48372536086. RMSE_test:  0.9931466250669805\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 773347.084365656. RMSE_train: 0.9830976017004779\n",
      "SE_test:  197291.4432271786. RMSE_test:  0.9931037377101916\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 773245.8024023919. RMSE_train: 0.9830332235464296\n",
      "SE_test:  197275.87785216625. RMSE_test:  0.993064561310155\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 773152.9926135654. RMSE_train: 0.9829742268836483\n",
      "SE_test:  197261.67952058633. RMSE_test:  0.9930288242657098\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 773068.0309974424. RMSE_train: 0.9829202159865744\n",
      "SE_test:  197248.7409756546. RMSE_test:  0.9929962569703723\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 772990.2981345217. RMSE_train: 0.9828707978758121\n",
      "SE_test:  197236.9575520789. RMSE_test:  0.992966596273422\n",
      "\n",
      "Iterations: 43\n",
      "SE_train: 772919.1893969608. RMSE_train: 0.9828255888290705\n",
      "SE_test:  197226.22863358774. RMSE_test:  0.9929395891579994\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 772854.1232917821. RMSE_train: 0.9827842197054256\n",
      "SE_test:  197216.45875319443. RMSE_test:  0.9929149955194377\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 772794.5477507015. RMSE_train: 0.98274633996314\n",
      "SE_test:  197207.55834232087. RMSE_test:  0.9928925900589896\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 772739.944435706. RMSE_train: 0.9827116204144347\n",
      "SE_test:  197199.44416567736. RMSE_test:  0.9928721633856784\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 772689.831281618. RMSE_train: 0.9826797548575502\n",
      "SE_test:  197192.03949408387. RMSE_test:  0.9928535224575792\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 772643.7635674655. RMSE_train: 0.9826504607714995\n",
      "SE_test:  197185.27407069673. RMSE_test:  0.9928364905021495\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 772601.3338238081. RMSE_train: 0.9826234792688082\n",
      "SE_test:  197179.08392357593. RMSE_test:  0.992820906548921\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 772562.1708661513. RMSE_train: 0.9825985744908167\n",
      "SE_test:  197173.4110705726. RMSE_test:  0.992806624690371\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 772525.9382080003. RMSE_train: 0.9825755326069198\n",
      "SE_test:  197168.2031549556. RMSE_test:  0.9927935131677793\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 772492.3320650815. RMSE_train: 0.9825541605524267\n",
      "SE_test:  197163.4130419868. RMSE_test:  0.9927814533582086\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 772461.0791187676. RMSE_train: 0.9825342846120778\n",
      "SE_test:  197158.99839941636. RMSE_test:  0.992770338720525\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 772431.9341693136. RMSE_train: 0.9825157489324499\n",
      "SE_test:  197154.92127882264. RMSE_test:  0.9927600737431423\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 772404.677773624. RMSE_train: 0.9824984140236475\n",
      "SE_test:  197151.14770951992. RMSE_test:  0.992750572923074\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 772379.1139371905. RMSE_train: 0.9824821552947101\n",
      "SE_test:  197147.64731271684. RMSE_test:  0.992741759795692\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 772355.0679051869. RMSE_train: 0.9824668616514719\n",
      "SE_test:  197144.39294074164. RMSE_test:  0.9927335660273703\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 772332.3840834938. RMSE_train: 0.9824524341765505\n",
      "SE_test:  197141.36034373307. RMSE_test:  0.9927259305770909\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 772310.9241049712. RMSE_train: 0.9824387849012973\n",
      "SE_test:  197138.52786456497. RMSE_test:  0.9927187989289851\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 772290.565048375. RMSE_train: 0.9824258356744914\n",
      "SE_test:  197135.87616167392. RMSE_test:  0.9927121223950022\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 61\n",
      "SE_train: 772271.197810836. RMSE_train: 0.9824135171284194\n",
      "SE_test:  197133.38795877039. RMSE_test:  0.9927058574851654\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 772252.7256287921. RMSE_train: 0.9824017677391497\n",
      "SE_test:  197131.04781991153. RMSE_test:  0.9926999653416\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 772235.0627413015. RMSE_train: 0.9823905329771747\n",
      "SE_test:  197128.8419478605. RMSE_test:  0.9926944112311271\n",
      "\n",
      "Iterations: 64\n",
      "SE_train: 772218.1331856207. RMSE_train: 0.9823797645420287\n",
      "SE_test:  197126.75800415978. RMSE_test:  0.9926891640924741\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 772201.8697163531. RMSE_train: 0.9823694196753743\n",
      "SE_test:  197124.7849486986. RMSE_test:  0.9926841961325246\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 772186.21283705. RMSE_train: 0.9823594605455126\n",
      "SE_test:  197122.91289695687. RMSE_test:  0.9926794824670386\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 772171.1099342164. RMSE_train: 0.9823498536969445\n",
      "SE_test:  197121.13299313438. RMSE_test:  0.9926750008013411\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 772156.5145045923. RMSE_train: 0.98234056955919\n",
      "SE_test:  197119.43729754142. RMSE_test:  0.9926707311468942\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 772142.3854661093. RMSE_train: 0.9823315820087758\n",
      "SE_test:  197117.8186865445. RMSE_test:  0.9926666555694621\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 772128.6865435102. RMSE_train: 0.9823228679786639\n",
      "SE_test:  197116.27076381046. RMSE_test:  0.9926627579657085\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 772115.385721496. RMSE_train: 0.9823144071105964\n",
      "SE_test:  197114.7877815744. RMSE_test:  0.9926590238650187\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 772102.4547576265. RMSE_train: 0.9823061814454142\n",
      "SE_test:  197113.36457067306. RMSE_test:  0.9926554402533827\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 772089.8687492464. RMSE_train: 0.9822981751477141\n",
      "SE_test:  197111.99647843654. RMSE_test:  0.9926519954170553\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 772077.6057475024. RMSE_train: 0.9822903742604381\n",
      "SE_test:  197110.6793135544. RMSE_test:  0.992648678803769\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 772065.6464138795. RMSE_train: 0.9822827664864883\n",
      "SE_test:  197109.40929696753. RMSE_test:  0.9926454808991143\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 772053.9737149632. RMSE_train: 0.9822753409946436\n",
      "SE_test:  197108.1830182611. RMSE_test:  0.9926423931167658\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 772042.5726501166. RMSE_train: 0.9822680882463994\n",
      "SE_test:  197106.99739683355. RMSE_test:  0.9926394077007296\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 772031.4300092555. RMSE_train: 0.9822609998419408\n",
      "SE_test:  197105.84964726976. RMSE_test:  0.9926365176381727\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 772020.5341574919. RMSE_train: 0.9822540683831985\n",
      "SE_test:  197104.7372485132. RMSE_test:  0.9926337165818168\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 772009.8748428429. RMSE_train: 0.9822472873515695\n",
      "SE_test:  197103.65791634514. RMSE_test:  0.9926309987806541\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 771999.4430255431. RMSE_train: 0.9822406509993714\n",
      "SE_test:  197102.60957883744. RMSE_test:  0.9926283590181505\n",
      "\n",
      "Iterations: 82\n",
      "SE_train: 771989.2307257667. RMSE_train: 0.9822341542530042\n",
      "SE_test:  197101.59035439458. RMSE_test:  0.9926257925569649\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 771979.2308885322. RMSE_train: 0.9822277926270349\n",
      "SE_test:  197100.5985321944. RMSE_test:  0.9926232950897088\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 771969.4372629543. RMSE_train: 0.9822215621474067\n",
      "SE_test:  197099.63255461078. RMSE_test:  0.9926208626946934\n",
      "\n",
      "Iterations: 85\n",
      "SE_train: 771959.8442954011. RMSE_train: 0.9822154592834893\n",
      "SE_test:  197098.69100157384. RMSE_test:  0.9926184917965545\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 771950.4470344135. RMSE_train: 0.982209480887608\n",
      "SE_test:  197097.7725765213. RMSE_test:  0.9926161791308847\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 771941.2410463667. RMSE_train: 0.9822036241414049\n",
      "SE_test:  197096.8760938239. RMSE_test:  0.992613921712574\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 771932.2223407143. RMSE_train: 0.9821978865082932\n",
      "SE_test:  197096.0004675584. RMSE_test:  0.9926117168075448\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 771923.3873038496. RMSE_train: 0.9821922656913906\n",
      "SE_test:  197095.14470143797. RMSE_test:  0.9926095619073997\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 771914.7326406309. RMSE_train: 0.9821867595963285\n",
      "SE_test:  197094.30787973222. RMSE_test:  0.992607454706561\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 771906.255323154. RMSE_train: 0.9821813662986683\n",
      "SE_test:  197093.4891592384. RMSE_test:  0.9926053930820571\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 771897.952545012. RMSE_train: 0.9821760840148078\n",
      "SE_test:  197092.68776199204. RMSE_test:  0.9926033750751692\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 771889.8216821916. RMSE_train: 0.9821709110771102\n",
      "SE_test:  197091.90296878983. RMSE_test:  0.9926013988751246\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 771881.8602581933. RMSE_train: 0.9821658459117166\n",
      "SE_test:  197091.1341133659. RMSE_test:  0.9925994628044333\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 771874.0659137934. RMSE_train: 0.982160887019313\n",
      "SE_test:  197090.38057714672. RMSE_test:  0.9925975653056832\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 771866.4363812708. RMSE_train: 0.9821560329587363\n",
      "SE_test:  197089.6417846185. RMSE_test:  0.9925957049298754\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 771858.969461641. RMSE_train: 0.9821512823324928\n",
      "SE_test:  197088.91719910764. RMSE_test:  0.9925938803258006\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 771851.663005802. RMSE_train: 0.9821466337747654\n",
      "SE_test:  197088.2063190109. RMSE_test:  0.9925920902305483\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 771844.5148981125. RMSE_train: 0.982142085940968\n",
      "SE_test:  197087.50867446678. RMSE_test:  0.992590333461125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "U_0,M_0,SE_0 = mat_fac(folded_data,X,0) # Done with 0.03,0.3,10,100. Gives 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\n",
      "SE_train: 5887336.435781592. RMSE_train: 2.7124943213551393\n",
      "SE_test:  317696.4057573767. RMSE_test:  1.2602207968103278\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 916106.1036405927. RMSE_train: 1.0699963561565438\n",
      "SE_test:  224134.37857936524. RMSE_test:  1.0585094247314788\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 749720.9223894099. RMSE_train: 0.9679640450782889\n",
      "SE_test:  204815.94580330243. RMSE_test:  1.0118645342634525\n",
      "\n",
      "Iterations: 3\n",
      "SE_train: 704307.019038756. RMSE_train: 0.9381891770974127\n",
      "SE_test:  196718.53138484817. RMSE_test:  0.9916607594114939\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 682228.2864577173. RMSE_train: 0.9233668343334028\n",
      "SE_test:  192007.02975202922. RMSE_test:  0.9797134182463044\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 667798.5910805106. RMSE_train: 0.9135496584888793\n",
      "SE_test:  188681.02032364858. RMSE_test:  0.9711908891720951\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 656564.4419998839. RMSE_train: 0.9058328987839566\n",
      "SE_test:  186052.88716615958. RMSE_test:  0.9644033236710681\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 646992.0490840077. RMSE_train: 0.8992053500730929\n",
      "SE_test:  183859.75166668423. RMSE_test:  0.9587024255281588\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 638524.120341953. RMSE_train: 0.8933015017546446\n",
      "SE_test:  181985.84251554485. RMSE_test:  0.9538043380699647\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 630909.4202710935. RMSE_train: 0.8879590060287836\n",
      "SE_test:  180361.70594628583. RMSE_test:  0.9495386758176678\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 623978.3620667056. RMSE_train: 0.8830680566371569\n",
      "SE_test:  178934.61372684696. RMSE_test:  0.9457746551087602\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 617592.1340662714. RMSE_train: 0.8785374685722092\n",
      "SE_test:  177662.38996828455. RMSE_test:  0.9424064320744864\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 611638.2957484558. RMSE_train: 0.8742924844366545\n",
      "SE_test:  176512.0842941657. RMSE_test:  0.9393505914547703\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 606031.4590093556. RMSE_train: 0.8702759757135519\n",
      "SE_test:  175458.98545566635. RMSE_test:  0.9365442427771379\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 600711.4290791256. RMSE_train: 0.8664477091585151\n",
      "SE_test:  174485.36399003858. RMSE_test:  0.933942187240905\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 595638.8886219768. RMSE_train: 0.862781715381653\n",
      "SE_test:  173579.0105161955. RMSE_test:  0.9315133764799154\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 590789.8393762783. RMSE_train: 0.8592626196035551\n",
      "SE_test:  172731.7353482365. RMSE_test:  0.9292371403469986\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 586150.0744975775. RMSE_train: 0.855881861609507\n",
      "SE_test:  171938.00589037625. RMSE_test:  0.9270996867203183\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 581710.6475260574. RMSE_train: 0.8526345303954462\n",
      "SE_test:  171193.85469234115. RMSE_test:  0.9250912580526216\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 577464.7655215425. RMSE_train: 0.8495171594659171\n",
      "SE_test:  170496.11086999392. RMSE_test:  0.9232041115888081\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 573406.0283216516. RMSE_train: 0.8465264602609897\n",
      "SE_test:  169841.93070328687. RMSE_test:  0.9214312786194012\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 569527.6585178289. RMSE_train: 0.8436587601190103\n",
      "SE_test:  169228.55814283885. RMSE_test:  0.919765930546441\n",
      "\n",
      "Iterations: 22\n",
      "SE_train: 565822.324484561. RMSE_train: 0.8409098693854954\n",
      "SE_test:  168653.23607018884. RMSE_test:  0.9182011469253184\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 562282.2481252595. RMSE_train: 0.8382751589160582\n",
      "SE_test:  168113.20189125722. RMSE_test:  0.9167299104653965\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 558899.4079061509. RMSE_train: 0.8357497110923668\n",
      "SE_test:  167605.72155149688. RMSE_test:  0.91534520652256\n",
      "\n",
      "Iterations: 25\n",
      "SE_train: 555665.7425049471. RMSE_train: 0.8333284745515536\n",
      "SE_test:  167128.13474446008. RMSE_test:  0.9140401536556197\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 552573.3186330644. RMSE_train: 0.8310063948306283\n",
      "SE_test:  166677.8973881398. RMSE_test:  0.9128081272161697\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 549614.4557344397. RMSE_train: 0.8287785145408604\n",
      "SE_test:  166252.6155180049. RMSE_test:  0.911642859669174\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 546781.81187188. RMSE_train: 0.8266400454546421\n",
      "SE_test:  165850.06906636193. RMSE_test:  0.9105385131081056\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 544068.4381391021. RMSE_train: 0.8245864173598434\n",
      "SE_test:  165468.22603376053. RMSE_test:  0.9094897250651064\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 541467.8085995639. RMSE_train: 0.822613308482086\n",
      "SE_test:  165105.24836076674. RMSE_test:  0.9084916310070741\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 538973.8315091506. RMSE_train: 0.8207166614979627\n",
      "SE_test:  164759.491009864. RMSE_test:  0.9075398675452375\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 536580.8463638792. RMSE_train: 0.8188926883636752\n",
      "SE_test:  164429.4957149771. RMSE_test:  0.9066305603085768\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 534283.6103623144. RMSE_train: 0.8171378665509103\n",
      "SE_test:  164113.98071580232. RMSE_test:  0.9057603000938825\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 532077.2771867336. RMSE_train: 0.8154489288255624\n",
      "SE_test:  163811.82763871097. RMSE_test:  0.9049261105107591\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 529957.3705113432. RMSE_train: 0.8138228483749926\n",
      "SE_test:  163522.06653582762. RMSE_test:  0.9041254099481835\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 527919.7542691298. RMSE_train: 0.8122568208370939\n",
      "SE_test:  163243.85995137933. RMSE_test:  0.9033559703101719\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 525960.6013934147. RMSE_train: 0.8107482445688016\n",
      "SE_test:  162976.48674605414. RMSE_test:  0.9026158745943766\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 524076.36245834164. RMSE_train: 0.8092947002862589\n",
      "SE_test:  162719.3262731236. RMSE_test:  0.9019034750130297\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 522263.7353530747. RMSE_train: 0.8078939309987153\n",
      "SE_test:  162471.8433655756. RMSE_test:  0.9012173529847431\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 520519.6368412797. RMSE_train: 0.8065438229473644\n",
      "SE_test:  162233.5744648323. RMSE_test:  0.9005562819683609\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 518841.17658240866. RMSE_train: 0.8052423880511214\n",
      "SE_test:  162004.11510307042. RMSE_test:  0.8999191937788132\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 517225.6339436004. RMSE_train: 0.8039877481695024\n",
      "SE_test:  161783.10884710465. RMSE_test:  0.8993051487324328\n",
      "\n",
      "Iterations: 43\n",
      "SE_train: 515670.43772016885. RMSE_train: 0.8027781213266055\n",
      "SE_test:  161570.23772616903. RMSE_test:  0.8987133097268359\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 514173.1487182124. RMSE_train: 0.8016118099080569\n",
      "SE_test:  161365.21409895737. RMSE_test:  0.8981429201693077\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 512731.44503259595. RMSE_train: 0.8004871907437435\n",
      "SE_test:  161167.7738681426. RMSE_test:  0.8975932855313344\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 511343.1097793903. RMSE_train: 0.7994027069254842\n",
      "SE_test:  160977.67092058054. RMSE_test:  0.8970637582182827\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 510006.020999548. RMSE_train: 0.7983568611699293\n",
      "SE_test:  160794.67265630164. RMSE_test:  0.8965537253963597\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 508718.14343814494. RMSE_train: 0.7973482105217448\n",
      "SE_test:  160618.55646544643. RMSE_test:  0.8960625994035862\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 507477.5219081081. RMSE_train: 0.7963753621907569\n",
      "SE_test:  160449.10701672037. RMSE_test:  0.8955898103799352\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 506282.2759648158. RMSE_train: 0.795436970326078\n",
      "SE_test:  160286.1142302728. RMSE_test:  0.8951348007744391\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 505130.5956426825. RMSE_train: 0.7945317335459137\n",
      "SE_test:  160129.37182001295. RMSE_test:  0.8946970214179978\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 504020.7380324375. RMSE_train: 0.7936583930603412\n",
      "SE_test:  159978.67630355933. RMSE_test:  0.8942759288850478\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 502951.02450798237. RMSE_train: 0.7928157312455391\n",
      "SE_test:  159833.82639069468. RMSE_test:  0.8938709839007093\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 501919.83843949146. RMSE_train: 0.7920025705477829\n",
      "SE_test:  159694.62267345795. RMSE_test:  0.8934816505827103\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 500925.62325911934. RMSE_train: 0.791217772617325\n",
      "SE_test:  159560.86755153447. RMSE_test:  0.8931073963355625\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 499966.8807692291. RMSE_train: 0.7904602375896097\n",
      "SE_test:  159432.36533640922. RMSE_test:  0.8927476922408906\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 499042.1696083477. RMSE_train: 0.7897289034503145\n",
      "SE_test:  159308.92248611487. RMSE_test:  0.8924020138104534\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 498150.1038092558. RMSE_train: 0.7890227454351862\n",
      "SE_test:  159190.3479299035. RMSE_test:  0.8920698419887904\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 497289.35140166455. RMSE_train: 0.788340775429419\n",
      "SE_test:  159076.45344875174. RMSE_test:  0.8917506643104128\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 496458.6330265431. RMSE_train: 0.7876820413425367\n",
      "SE_test:  158967.0540835203. RMSE_test:  0.8914439761326968\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 61\n",
      "SE_train: 495656.7205407743. RMSE_train: 0.7870456264437062\n",
      "SE_test:  158861.9685479496. RMSE_test:  0.8911492818804354\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 494882.4356007058. RMSE_train: 0.7864306486500915\n",
      "SE_test:  158761.01962821974. RMSE_test:  0.8908660962506103\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 494134.6482193413. RMSE_train: 0.7858362597656541\n",
      "SE_test:  158664.0345551547. RMSE_test:  0.8905939453380545\n",
      "\n",
      "Iterations: 64\n",
      "SE_train: 493412.27529790316. RMSE_train: 0.7852616446724966\n",
      "SE_test:  158570.84533885287. RMSE_test:  0.8903323676530365\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 492714.2791358558. RMSE_train: 0.784706020479465\n",
      "SE_test:  158481.28905863684. RMSE_test:  0.8900809150105145\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 492039.6659247316. RMSE_train: 0.7841686356336889\n",
      "SE_test:  158395.2081041288. RMSE_test:  0.8898391532790119\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 491387.4842344221. RMSE_train: 0.7836487690033488\n",
      "SE_test:  158312.4503653978. RMSE_test:  0.8896066629831131\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 490756.82349859184. RMSE_train: 0.7831457289383383\n",
      "SE_test:  158232.8693722641. RMSE_test:  0.8893830397596308\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 490146.81250734115. RMSE_train: 0.7826588523166166\n",
      "SE_test:  158156.32438405787. RMSE_test:  0.8891678946709569\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 489556.61791398434. RMSE_train: 0.7821875035830095\n",
      "SE_test:  158082.68043249293. RMSE_test:  0.8889608543829904\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 488985.44276256213. RMSE_train: 0.7817310737869774\n",
      "SE_test:  158011.8083210513. RMSE_test:  0.8887615612171543\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 488432.5250406263. RMSE_train: 0.7812889796241527\n",
      "SE_test:  157943.58458485006. RMSE_test:  0.8885696730876789\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 487897.1362622445. RMSE_train: 0.780860662486733\n",
      "SE_test:  157877.89141535052. RMSE_test:  0.8883848633364622\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 487378.5800841335. RMSE_train: 0.7804455875261248\n",
      "SE_test:  157814.6165542192. RMSE_test:  0.8882068204777126\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 486876.19095779513. RMSE_train: 0.780043242731153\n",
      "SE_test:  157753.65316099237. RMSE_test:  0.88803524786557\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 486389.3328187699. RMSE_train: 0.7796531380236855\n",
      "SE_test:  157694.89965876078. RMSE_test:  0.8878698632967014\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 485917.3978147607. RMSE_train: 0.7792748043739751\n",
      "SE_test:  157638.25956202197. RMSE_test:  0.887710398559693\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 485459.80507284356. RMSE_train: 0.7789077929367352\n",
      "SE_test:  157583.6412905988. RMSE_test:  0.88755659894237\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 485015.9995063703. RMSE_train: 0.7785516742092242\n",
      "SE_test:  157530.95797327248. RMSE_test:  0.8874082227074798\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 484585.45066126494. RMSE_train: 0.7782060372118345\n",
      "SE_test:  157480.1272442627. RMSE_test:  0.887265040545731\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 484167.65160206915. RMSE_train: 0.7778704886921595\n",
      "SE_test:  157431.07103549887. RMSE_test:  0.8871268350146481\n",
      "\n",
      "Iterations: 82\n",
      "SE_train: 483762.11783690617. RMSE_train: 0.7775446523525117\n",
      "SE_test:  157383.71536737875. RMSE_test:  0.8869933999710017\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 483368.38628210005. RMSE_train: 0.7772281681020792\n",
      "SE_test:  157337.99014008636. RMSE_test:  0.8868645400028166\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 482986.01426497055. RMSE_train: 0.7769206913330875\n",
      "SE_test:  157293.82892746534. RMSE_test:  0.8867400698667381\n",
      "\n",
      "Iterations: 85\n",
      "SE_train: 482614.57856555673. RMSE_train: 0.7766218922220873\n",
      "SE_test:  157251.16877512707. RMSE_test:  0.8866198139356408\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 482253.6744964732. RMSE_train: 0.7763314550562076\n",
      "SE_test:  157209.9500039149. RMSE_test:  0.88650360565978\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 481902.91502054175. RMSE_train: 0.7760490775845333\n",
      "SE_test:  157170.11602006236. RMSE_test:  0.8863912870453957\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 481561.92990592. RMSE_train: 0.7757744703947969\n",
      "SE_test:  157131.61313255542. RMSE_test:  0.8862827081523306\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 481230.36491830903. RMSE_train: 0.7755073563154313\n",
      "SE_test:  157094.39037856576. RMSE_test:  0.8861777266132251\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 480907.88104956184. RMSE_train: 0.7752474698427966\n",
      "SE_test:  157058.39935714944. RMSE_test:  0.8860762071749463\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 480594.1537820347. RMSE_train: 0.7749945565933777\n",
      "SE_test:  157023.59407157113. RMSE_test:  0.8859780212633678\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 480288.87238827796. RMSE_train: 0.7747483727809378\n",
      "SE_test:  156989.93078028513. RMSE_test:  0.8858830465716815\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 479991.739264522. RMSE_train: 0.7745086847176633\n",
      "SE_test:  156957.3678565458. RMSE_test:  0.8857911666722487\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 479702.4692979319. RMSE_train: 0.7742752683395426\n",
      "SE_test:  156925.86565653497. RMSE_test:  0.8857022706517502\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 479420.7892657571. RMSE_train: 0.7740479087547077\n",
      "SE_test:  156895.38639575057. RMSE_test:  0.8856162527689876\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 479146.4372656887. RMSE_train: 0.7738263998144096\n",
      "SE_test:  156865.8940334099. RMSE_test:  0.8855330121347005\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 478879.1621761251. RMSE_train: 0.7736105437057825\n",
      "SE_test:  156837.35416455058. RMSE_test:  0.8854524524125668\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 478618.7231452654. RMSE_train: 0.7734001505657171\n",
      "SE_test:  156809.7339193716. RMSE_test:  0.8853744815401462\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 478364.8891071115. RMSE_train: 0.7731950381144636\n",
      "SE_test:  156783.001869595. RMSE_test:  0.8852990114691955\n",
      "\n",
      "Iterations: 0\n",
      "SE_train: 6011829.016398525. RMSE_train: 2.741023257236948\n",
      "SE_test:  320311.8435865003. RMSE_test:  1.265394389552391\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 919268.9908883475. RMSE_train: 1.0718418638793643\n",
      "SE_test:  223778.59776280026. RMSE_test:  1.0576663323653501\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 749218.9400886135. RMSE_train: 0.9676399363559859\n",
      "SE_test:  204281.43755575366. RMSE_test:  1.010540814269238\n",
      "\n",
      "Iterations: 3\n",
      "SE_train: 703203.3045729231. RMSE_train: 0.9374537741161677\n",
      "SE_test:  196084.02034304442. RMSE_test:  0.9900577037331262\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 680695.0463307968. RMSE_train: 0.9223286632102845\n",
      "SE_test:  191270.23746551722. RMSE_test:  0.97782943080298\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 665861.6737063564. RMSE_train: 0.9122238432213422\n",
      "SE_test:  187854.6728835937. RMSE_test:  0.969059419449963\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 654336.0022890387. RMSE_train: 0.904294352367301\n",
      "SE_test:  185170.62168444783. RMSE_test:  0.9621115944062933\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 644649.5847361302. RMSE_train: 0.8975760669341718\n",
      "SE_test:  182957.73551261795. RMSE_test:  0.9563454460991133\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 636219.763105988. RMSE_train: 0.8916881356499707\n",
      "SE_test:  181088.03855988954. RMSE_test:  0.951446314975516\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 628728.606165762. RMSE_train: 0.8864230091211935\n",
      "SE_test:  179479.6211953707. RMSE_test:  0.9472115349495834\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 621953.2422558097. RMSE_train: 0.8816338947497675\n",
      "SE_test:  178072.89558896856. RMSE_test:  0.9434922048757498\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 615728.3601658972. RMSE_train: 0.8772108386515339\n",
      "SE_test:  176823.48836234937. RMSE_test:  0.9401764813748318\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 609934.3080231951. RMSE_train: 0.8730737717333554\n",
      "SE_test:  175698.7396281894. RMSE_test:  0.9371815476191235\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 604487.7312641464. RMSE_train: 0.8691668535822774\n",
      "SE_test:  174674.96651540036. RMSE_test:  0.9344471426302849\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 599332.1880479166. RMSE_train: 0.865452450104443\n",
      "SE_test:  173734.98896100099. RMSE_test:  0.9319294830442472\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 594429.4612996078. RMSE_train: 0.8619053437889586\n",
      "SE_test:  172866.01613554603. RMSE_test:  0.9295959388195182\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 589752.643723805. RMSE_train: 0.8585080238932351\n",
      "SE_test:  172058.09122634755. RMSE_test:  0.9274210656798743\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 585281.5573379415. RMSE_train: 0.8552475328935463\n",
      "SE_test:  171303.1419983013. RMSE_test:  0.9253841793854164\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 581000.252141019. RMSE_train: 0.852113745125028\n",
      "SE_test:  170594.50264905588. RMSE_test:  0.9234681513867644\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 576895.8347949053. RMSE_train: 0.8490985750380835\n",
      "SE_test:  169926.69981856053. RMSE_test:  0.9216588921715906\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 572957.8914936188. RMSE_train: 0.8461956006138173\n",
      "SE_test:  169295.33157497967. RMSE_test:  0.9199450717833797\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 569178.0551235704. RMSE_train: 0.8433997812629226\n",
      "SE_test:  168696.94511365105. RMSE_test:  0.9183178267711851\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 22\n",
      "SE_train: 565549.5521694226. RMSE_train: 0.840707151524065\n",
      "SE_test:  168128.8843952052. RMSE_test:  0.9167703767640218\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 562066.7318464813. RMSE_train: 0.8381144929354314\n",
      "SE_test:  167589.11613410164. RMSE_test:  0.9152975740403821\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 558724.634984534. RMSE_train: 0.8356190276119931\n",
      "SE_test:  167076.05543082216. RMSE_test:  0.913895444855944\n",
      "\n",
      "Iterations: 25\n",
      "SE_train: 555518.6512634724. RMSE_train: 0.8332181713392477\n",
      "SE_test:  166588.41065022463. RMSE_test:  0.9125607772334797\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 552444.2833537197. RMSE_train: 0.8309093620936441\n",
      "SE_test:  166125.05942021403. RMSE_test:  0.9112907891620345\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 549497.0100485225. RMSE_train: 0.8286899600454795\n",
      "SE_test:  165684.95938249028. RMSE_test:  0.9100828886595786\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 546672.2262586516. RMSE_train: 0.8265572040052044\n",
      "SE_test:  165267.0912258194. RMSE_test:  0.9089345202582265\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 543965.2347778812. RMSE_train: 0.8245082064952477\n",
      "SE_test:  164870.42818693424. RMSE_test:  0.9078430829892199\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 541371.268415357. RMSE_train: 0.8225399719150812\n",
      "SE_test:  164493.92513801658. RMSE_test:  0.9068059016856822\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 538885.5270587703. RMSE_train: 0.8206494264132752\n",
      "SE_test:  164136.5207733803. RMSE_test:  0.9058202342101845\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 536503.2198180485. RMSE_train: 0.8188334520803904\n",
      "SE_test:  163797.1475175317. RMSE_test:  0.9048833000406479\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 534219.606566281. RMSE_train: 0.8170889211118949\n",
      "SE_test:  163474.74508763236. RMSE_test:  0.9039923191014584\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 532030.0358949747. RMSE_train: 0.8154127275841934\n",
      "SE_test:  163168.2748642435. RMSE_test:  0.9031445529945141\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 529929.9780853818. RMSE_train: 0.8138018156736544\n",
      "SE_test:  162876.7332311427. RMSE_test:  0.9023373435099535\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 527915.0525629848. RMSE_train: 0.812253203808788\n",
      "SE_test:  162599.16281292928. RMSE_test:  0.9015681453940576\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 525981.0497595002. RMSE_train: 0.810764004604565\n",
      "SE_test:  162334.6610920782. RMSE_test:  0.9008345518759379\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 524123.94754740095. RMSE_train: 0.8093314406250918\n",
      "SE_test:  162082.38626774662. RMSE_test:  0.9001343125138684\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 522339.9225499677. RMSE_train: 0.8079528561405875\n",
      "SE_test:  161841.56046855135. RMSE_test:  0.8994653436252207\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 520625.3567180846. RMSE_train: 0.8066257251259189\n",
      "SE_test:  161611.47058685948. RMSE_test:  0.8988257320070607\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 518976.8396272357. RMSE_train: 0.8053476558084927\n",
      "SE_test:  161391.46708938983. RMSE_test:  0.8982137329087393\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 517391.166996227. RMSE_train: 0.8041163921219037\n",
      "SE_test:  161180.9611987778. RMSE_test:  0.8976277633393311\n",
      "\n",
      "Iterations: 43\n",
      "SE_train: 515865.3359626603. RMSE_train: 0.8029298124579392\n",
      "SE_test:  160979.4208458632. RMSE_test:  0.8970663918160894\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 514396.5376704899. RMSE_train: 0.8017859261343576\n",
      "SE_test:  160786.36577499806. RMSE_test:  0.8965283256188153\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 512982.1477298545. RMSE_train: 0.800682868007517\n",
      "SE_test:  160601.3621500137. RMSE_test:  0.8960123965241643\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 511619.7150985093. RMSE_train: 0.7996188916571686\n",
      "SE_test:  160424.01696439585. RMSE_test:  0.8955175458751411\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 510306.94990885037. RMSE_train: 0.7985923615565556\n",
      "SE_test:  160253.97250910703. RMSE_test:  0.8950428097040848\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 509041.7107226267. RMSE_train: 0.7976017446127179\n",
      "SE_test:  160090.90109955418. RMSE_test:  0.8945873044841675\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 507821.99164511263. RMSE_train: 0.7966456014260004\n",
      "SE_test:  159934.50021223258. RMSE_test:  0.8941502139428773\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 506645.90966766316. RMSE_train: 0.7957225775710296\n",
      "SE_test:  159784.4881337986. RMSE_test:  0.8937307772374938\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 505511.692542619. RMSE_train: 0.7948313951521182\n",
      "SE_test:  159640.60018252092. RMSE_test:  0.8933282786723896\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 504417.66742503823. RMSE_train: 0.793970844832343\n",
      "SE_test:  159502.58552479502. RMSE_test:  0.8929420390328311\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 503362.2504504193. RMSE_train: 0.7931397784844101\n",
      "SE_test:  159370.20457893517. RMSE_test:  0.8925714085234974\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 502343.93735233555. RMSE_train: 0.7923371025597374\n",
      "SE_test:  159243.22697437022. RMSE_test:  0.8922157612311539\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 501361.29516972497. RMSE_train: 0.7915617722287458\n",
      "SE_test:  159121.43001665323. RMSE_test:  0.8918744909799009\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 500412.9550437973. RMSE_train: 0.7908127863050269\n",
      "SE_test:  159004.59759710878. RMSE_test:  0.8915470084135887\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 499497.60606498545. RMSE_train: 0.7900891829335878\n",
      "SE_test:  158892.51947938933. RMSE_test:  0.8912327391203365\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 498613.990099844. RMSE_train: 0.7893900359978767\n",
      "SE_test:  158784.99089353313. RMSE_test:  0.8909311226082334\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 497760.8975062494. RMSE_train: 0.7887144521818558\n",
      "SE_test:  158681.81236977273. RMSE_test:  0.8906416119449331\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 496937.1636323287. RMSE_train: 0.788061568611785\n",
      "SE_test:  158582.78974913334. RMSE_test:  0.8903636738864595\n",
      "\n",
      "Iterations: 61\n",
      "SE_train: 496141.6659874851. RMSE_train: 0.7874305509955158\n",
      "SE_test:  158487.73431442425. RMSE_test:  0.8900967893382715\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 495373.3219757141. RMSE_train: 0.7868205921773687\n",
      "SE_test:  158396.4629931438. RMSE_test:  0.8898404540133379\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 494631.08708468016. RMSE_train: 0.7862309110282452\n",
      "SE_test:  158308.79859220554. RMSE_test:  0.8895941791751265\n",
      "\n",
      "Iterations: 64\n",
      "SE_train: 493913.95343380474. RMSE_train: 0.7856607515975135\n",
      "SE_test:  158224.57003273122. RMSE_test:  0.8893574923765551\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 493220.94859440456. RMSE_train: 0.7851093824602378\n",
      "SE_test:  158143.61256141466. RMSE_test:  0.8891299381289717\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 492551.13460805. RMSE_train: 0.7845760962031717\n",
      "SE_test:  158065.76792160215. RMSE_test:  0.8889110784537884\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 491903.60714032047. RMSE_train: 0.7840602090012089\n",
      "SE_test:  157990.88447411387. RMSE_test:  0.8887004932886823\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 491277.49472051056. RMSE_train: 0.7835610602462708\n",
      "SE_test:  157918.8172625808. RMSE_test:  0.8884977807336193\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 490671.9580279008. RMSE_train: 0.7830780121983418\n",
      "SE_test:  157849.4280223894. RMSE_test:  0.888302557134119\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 490086.18919583526. RMSE_train: 0.7826104496366371\n",
      "SE_test:  157782.58513547445. RMSE_test:  0.888114457008068\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 489519.4111129726. RMSE_train: 0.7821577794952183\n",
      "SE_test:  157718.16353541115. RMSE_test:  0.8879331328286477\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 488970.8767086076. RMSE_train: 0.7817194304732893\n",
      "SE_test:  157656.04456868296. RMSE_test:  0.8877582546799984\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 488439.86821434065. RMSE_train: 0.7812948526146286\n",
      "SE_test:  157596.11581882558. RMSE_test:  0.8875895098045975\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 487925.69639910135. RMSE_train: 0.780883516854357\n",
      "SE_test:  157538.2709004568. RMSE_test:  0.8874266020622403\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 487427.69977759494. RMSE_train: 0.7804849145336588\n",
      "SE_test:  157482.40923001996. RMSE_test:  0.88726925132002\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 486945.2437951637. RMSE_train: 0.7800985568853971\n",
      "SE_test:  157428.4357797114. RMSE_test:  0.8871171927917249\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 486477.7199924781. RMSE_train: 0.7797239744938933\n",
      "SE_test:  157376.26082047253. RMSE_test:  0.8869701763434219\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 486024.54515572963. RMSE_train: 0.7793607167339374\n",
      "SE_test:  157325.79965923767. RMSE_test:  0.8868279657800613\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 485585.1604572746. RMSE_train: 0.7790083511935126\n",
      "SE_test:  157276.97237489448. RMSE_test:  0.8866903381258702\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 485159.030592119. RMSE_train: 0.7786664630850584\n",
      "SE_test:  157229.70355663804. RMSE_test:  0.8865570829091189\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 484745.64291586005. RMSE_train: 0.7783346546502685\n",
      "SE_test:  157183.92204768874. RMSE_test:  0.8864280014598318\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 82\n",
      "SE_train: 484344.50658780726. RMSE_train: 0.7780125445618887\n",
      "SE_test:  157139.56069678877. RMSE_test:  0.8863029062274425\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 483955.1517244503. RMSE_train: 0.7776997673271233\n",
      "SE_test:  157096.55611910525. RMSE_test:  0.8861816201231658\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 483577.12856656633. RMSE_train: 0.7773959726957373\n",
      "SE_test:  157054.848467888. RMSE_test:  0.8860639758910593\n",
      "\n",
      "Iterations: 85\n",
      "SE_train: 483210.00666231796. RMSE_train: 0.7771008250751685\n",
      "SE_test:  157014.3812175274. RMSE_test:  0.8859498155097504\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 482853.374069913. RMSE_train: 0.776814002955921\n",
      "SE_test:  156975.10095860795. RMSE_test:  0.8858389896266565\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 482506.83658088144. RMSE_train: 0.7765351983484743\n",
      "SE_test:  156936.95720490502. RMSE_test:  0.8857313570246871\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 482170.01696565945. RMSE_train: 0.7762641162334264\n",
      "SE_test:  156899.90221228058. RMSE_test:  0.8856267841214179\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 481842.55424290575. RMSE_train: 0.7760004740263613\n",
      "SE_test:  156863.8908092104. RMSE_test:  0.8855251445001029\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 481524.1029725167. RMSE_train: 0.7757440010577321\n",
      "SE_test:  156828.88023846675. RMSE_test:  0.8854263184712723\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 481214.33257347. RMSE_train: 0.77549443806897\n",
      "SE_test:  156794.83000938818. RMSE_test:  0.885330192663411\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 480912.9266660745. RMSE_train: 0.7752515367247603\n",
      "SE_test:  156761.7017602203. RMSE_test:  0.8852366596413364\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 480619.5824388045. RMSE_train: 0.7750150591418901\n",
      "SE_test:  156729.45912990283. RMSE_test:  0.8851456175505913\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 480334.01003975974. RMSE_train: 0.774784777434945\n",
      "SE_test:  156698.0676385699. RMSE_test:  0.8850569697858429\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 480055.9319916106. RMSE_train: 0.7745604732781635\n",
      "SE_test:  156667.49457626374. RMSE_test:  0.88497062468194\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 479785.08263056853. RMSE_train: 0.7743419374840935\n",
      "SE_test:  156637.70889915945. RMSE_test:  0.8848864952256963\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 479521.20756820403. RMSE_train: 0.7741289695982996\n",
      "SE_test:  156608.68113277125. RMSE_test:  0.8848044987869528\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 479264.06317567016. RMSE_train: 0.7739213775099436\n",
      "SE_test:  156580.3832815722. RMSE_test:  0.8847245568673568\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 479013.4160900364. RMSE_train: 0.7737189770781717\n",
      "SE_test:  156552.78874452508. RMSE_test:  0.8846465948654784\n",
      "\n",
      "Iterations: 0\n",
      "SE_train: 6228729.60053084. RMSE_train: 2.7900317744481047\n",
      "SE_test:  326577.98167095106. RMSE_test:  1.2777116550573242\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 929529.896495076. RMSE_train: 1.077807227778044\n",
      "SE_test:  225291.58405189912. RMSE_test:  1.06123579555281\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 751863.7473795891. RMSE_train: 0.9693463578249967\n",
      "SE_test:  205532.0335206879. RMSE_test:  1.0136293229176734\n",
      "\n",
      "Iterations: 3\n",
      "SE_train: 705214.5518392451. RMSE_train: 0.9387934330010989\n",
      "SE_test:  197531.73285582877. RMSE_test:  0.9937058415377498\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 683213.2276672557. RMSE_train: 0.9240331318551456\n",
      "SE_test:  193006.3609149438. RMSE_test:  0.9822571915973564\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 669175.9456215966. RMSE_train: 0.9144912849348807\n",
      "SE_test:  189863.08724339222. RMSE_test:  0.9742259090331034\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 658284.5282144962. RMSE_train: 0.9070186860587711\n",
      "SE_test:  187351.05012484486. RMSE_test:  0.9677595637986877\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 648776.7100529538. RMSE_train: 0.9004446787205257\n",
      "SE_test:  185175.67577662185. RMSE_test:  0.9621247243711221\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 640045.4333010503. RMSE_train: 0.8943650345217931\n",
      "SE_test:  183234.54978013804. RMSE_test:  0.9570686459278438\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 631934.8934890978. RMSE_train: 0.8886803524214589\n",
      "SE_test:  181492.8301640931. RMSE_test:  0.9525091198301253\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 624400.562606039. RMSE_train: 0.8833667599149965\n",
      "SE_test:  179927.93832078937. RMSE_test:  0.9483938037200004\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 617395.5438255371. RMSE_train: 0.8783976306197843\n",
      "SE_test:  178516.83923327565. RMSE_test:  0.9446675567838041\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 610864.2488168422. RMSE_train: 0.8737390873839627\n",
      "SE_test:  177237.4861726356. RMSE_test:  0.9412764581011028\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 604754.7136760374. RMSE_train: 0.8693587736445817\n",
      "SE_test:  176070.86880422363. RMSE_test:  0.9381734959080591\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 599023.4325903909. RMSE_train: 0.8652294956259682\n",
      "SE_test:  175001.4271776336. RMSE_test:  0.935319957538245\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 593634.3951427774. RMSE_train: 0.8613287395744856\n",
      "SE_test:  174016.5867573678. RMSE_test:  0.9326844347009041\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 588556.8582726497. RMSE_train: 0.8576372246485693\n",
      "SE_test:  173106.10153760467. RMSE_test:  0.9302412506674224\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 583763.7312797465. RMSE_train: 0.8541378450188479\n",
      "SE_test:  172261.48074969888. RMSE_test:  0.927969055071013\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 579230.7232947244. RMSE_train: 0.850815131492694\n",
      "SE_test:  171475.5576977393. RMSE_test:  0.9258497593862278\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 574935.9421515219. RMSE_train: 0.8476550233976539\n",
      "SE_test:  170742.18669432015. RMSE_test:  0.9238677891431865\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 570859.6927031451. RMSE_train: 0.8446447754361772\n",
      "SE_test:  170056.0377000296. RMSE_test:  0.9220095808341943\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 566984.3478081491. RMSE_train: 0.8417729103608269\n",
      "SE_test:  169412.45862590367. RMSE_test:  0.9202632489649716\n",
      "\n",
      "Iterations: 22\n",
      "SE_train: 563294.2368735047. RMSE_train: 0.8390291785151318\n",
      "SE_test:  168807.3804594487. RMSE_test:  0.9186183602356168\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 559775.5262430181. RMSE_train: 0.8364045059534776\n",
      "SE_test:  168237.2468828255. RMSE_test:  0.9170657677579209\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 556416.0789587965. RMSE_train: 0.8338909222097128\n",
      "SE_test:  167698.9563105803. RMSE_test:  0.9155974741220246\n",
      "\n",
      "Iterations: 25\n",
      "SE_train: 553205.2907612378. RMSE_train: 0.8314814655491495\n",
      "SE_test:  167189.80947826884. RMSE_test:  0.914206505636995\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 550133.9068152964. RMSE_train: 0.829170069218822\n",
      "SE_test:  166707.45954529278. RMSE_test:  0.9128867901581326\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 547193.8286795506. RMSE_train: 0.8269514360753819\n",
      "SE_test:  166249.86413981157. RMSE_test:  0.9116330374619547\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 544377.9229256489. RMSE_train: 0.8248209105344175\n",
      "SE_test:  165815.24006286918. RMSE_test:  0.9104406245696992\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 541679.8419765236. RMSE_train: 0.8227743562885074\n",
      "SE_test:  165402.02177259928. RMSE_test:  0.909305489482838\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 539093.8651284437. RMSE_train: 0.8208080463678876\n",
      "SE_test:  165008.82460750564. RMSE_test:  0.9082240363195069\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 536614.7644036085. RMSE_train: 0.81891856964141\n",
      "SE_test:  164634.4132715736. RMSE_test:  0.9071930536099795\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 534237.6966755342. RMSE_train: 0.8171027554063872\n",
      "SE_test:  164277.67561787312. RMSE_test:  0.9062096461336024\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 531958.1209245595. RMSE_train: 0.8153576156920296\n",
      "SE_test:  163937.6013699639. RMSE_test:  0.9052711795418169\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 529771.7377365036. RMSE_train: 0.8136803034896503\n",
      "SE_test:  163613.26517089098. RMSE_test:  0.9043752362792647\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 527674.4472347383. RMSE_train: 0.8120680843272752\n",
      "SE_test:  163303.81324661893. RMSE_test:  0.9035195809887665\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 525662.3213959466. RMSE_train: 0.8105183183350135\n",
      "SE_test:  163008.45298097536. RMSE_test:  0.9027021335773302\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 523731.5869430561. RMSE_train: 0.8090284500571594\n",
      "SE_test:  162726.44477750573. RMSE_test:  0.9019209483065352\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 521878.6155312126. RMSE_train: 0.8075960036057369\n",
      "SE_test:  162457.0956904988. RMSE_test:  0.9011741975424549\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 520099.9185861973. RMSE_train: 0.8062185811978078\n",
      "SE_test:  162199.75441550743. RMSE_test:  0.9004601590814209\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 518392.14479567437. RMSE_train: 0.804893863578889\n",
      "SE_test:  161953.80732306105. RMSE_test:  0.8997772062132563\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 516752.0788285524. RMSE_train: 0.8036196112558326\n",
      "SE_test:  161718.67529296028. RMSE_test:  0.8991237998780951\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 515176.6403309582. RMSE_train: 0.8023936658142066\n",
      "SE_test:  161493.811161703. RMSE_test:  0.8984984824186985\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 43\n",
      "SE_train: 513662.8826171227. RMSE_train: 0.8012139508735715\n",
      "SE_test:  161278.69763524903. RMSE_test:  0.8978998725349138\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 512207.99074542976. RMSE_train: 0.8000784724411436\n",
      "SE_test:  161072.8455491323. RMSE_test:  0.8973266611256686\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 510809.2788652244. RMSE_train: 0.7989853185749272\n",
      "SE_test:  160875.7923803673. RMSE_test:  0.8967776077632076\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 509464.18684590777. RMSE_train: 0.7979326583657637\n",
      "SE_test:  160687.10093459513. RMSE_test:  0.89625153759481\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 508170.27628191106. RMSE_train: 0.7969187403128815\n",
      "SE_test:  160506.35814814013. RMSE_test:  0.895747338510624\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 506925.226008412. RMSE_train: 0.7959418902012093\n",
      "SE_test:  160333.17395953476. RMSE_test:  0.8952639584564199\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 505726.82727891556. RMSE_train: 0.79500050860287\n",
      "SE_test:  160167.18021836484. RMSE_test:  0.8948004028061471\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 504572.9787509596. RMSE_train: 0.7940930681227\n",
      "SE_test:  160008.02961068362. RMSE_test:  0.8943557317402789\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 503461.6814128221. RMSE_train: 0.7932181104980868\n",
      "SE_test:  159855.3945903835. RMSE_test:  0.8939290576037405\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 502391.03356031125. RMSE_train: 0.792374243645369\n",
      "SE_test:  159708.96631330776. RMSE_test:  0.8935195422375176\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 501359.22590816166. RMSE_train: 0.7915601387260641\n",
      "SE_test:  159568.45357684628. RMSE_test:  0.8931263942944652\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 500364.5368959817. RMSE_train: 0.7907745272869162\n",
      "SE_test:  159433.58177136251. RMSE_test:  0.8927488665597265\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 499405.3282264442. RMSE_train: 0.7900161985100903\n",
      "SE_test:  159304.09185175705. RMSE_test:  0.8923862533015164\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 498480.0406544275. RMSE_train: 0.7892839965945753\n",
      "SE_test:  159179.73933828704. RMSE_test:  0.8920378876801665\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 497587.1900312556. RMSE_train: 0.7885768182779793\n",
      "SE_test:  159060.293354824. RMSE_test:  0.8917031392405931\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 496725.3635966674. RMSE_train: 0.7878936104983507\n",
      "SE_test:  158945.53571203956. RMSE_test:  0.8913814115112747\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 495893.216504445. RMSE_train: 0.7872333681898894\n",
      "SE_test:  158835.26004072092. RMSE_test:  0.891072139726287\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 495089.46856251796. RMSE_train: 0.7865951322019014\n",
      "SE_test:  158729.27097912936. RMSE_test:  0.8907747886831859\n",
      "\n",
      "Iterations: 61\n",
      "SE_train: 494312.9011672685. RMSE_train: 0.7859779873290389\n",
      "SE_test:  158627.38341610687. RMSE_test:  0.8904888507431981\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 493562.3544099142. RMSE_train: 0.78538106043899\n",
      "SE_test:  158529.42179023067. RMSE_test:  0.8902138439760819\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 492836.7243360424. RMSE_train: 0.7848035186859417\n",
      "SE_test:  158435.2194438753. RMSE_test:  0.8899493104478432\n",
      "\n",
      "Iterations: 64\n",
      "SE_train: 492134.96033941855. RMSE_train: 0.7842445677978445\n",
      "SE_test:  158344.61802992717. RMSE_test:  0.8896948146462146\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 491456.06267407513. RMSE_train: 0.7837034504275002\n",
      "SE_test:  158257.4669682565. RMSE_test:  0.8894499420368809\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 490799.08007172006. RMSE_train: 0.7831794445596425\n",
      "SE_test:  158173.62294835778. RMSE_test:  0.8892142977413567\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 490163.1074532595. RMSE_train: 0.7826718619673484\n",
      "SE_test:  158092.94947459098. RMSE_test:  0.8889875053273713\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 489547.2837257874. RMSE_train: 0.7821800467129575\n",
      "SE_test:  158015.31645007024. RMSE_test:  0.8887692057014243\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 488950.7896589021. RMSE_train: 0.781703373690491\n",
      "SE_test:  157940.5997956474. RMSE_test:  0.8885590560942147\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 488372.845835322. RMSE_train: 0.7812412472073025\n",
      "SE_test:  157868.68110037042. RMSE_test:  0.8883567291293697\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 487812.7106731303. RMSE_train: 0.7807930996044284\n",
      "SE_test:  157799.447300273. RMSE_test:  0.8881619119671663\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 487269.6785173306. RMSE_train: 0.7803583899152708\n",
      "SE_test:  157732.79038246413. RMSE_test:  0.8879743055151974\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 486743.07780051837. RMSE_train: 0.7799366025638264\n",
      "SE_test:  157668.60711187447. RMSE_test:  0.8877936236989616\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 486232.2692717501. RMSE_train: 0.7795272461030018\n",
      "SE_test:  157606.79877841024. RMSE_test:  0.8876195927864237\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 485736.6442945037. RMSE_train: 0.7791298519949117\n",
      "SE_test:  157547.27096221733. RMSE_test:  0.8874519507604093\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 485255.6232139036. RMSE_train: 0.7787439734343925\n",
      "SE_test:  157489.9333155286. RMSE_test:  0.8872904467348338\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 484788.6537936558. RMSE_train: 0.7783691842171121\n",
      "SE_test:  157434.69935921716. RMSE_test:  0.8871348404097437\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 484335.2097237075. RMSE_train: 0.7780050776540309\n",
      "SE_test:  157381.48629285258. RMSE_test:  0.8869849015620205\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 483894.7891981997. RMSE_train: 0.7776512655327482\n",
      "SE_test:  157330.21481693658. RMSE_test:  0.8868404095682345\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 483466.91356395767. RMSE_train: 0.7773073771267417\n",
      "SE_test:  157280.80896624035. RMSE_test:  0.8867011529568033\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 483051.12603916065. RMSE_train: 0.7769730582529668\n",
      "SE_test:  157233.19595334807. RMSE_test:  0.8865669289871069\n",
      "\n",
      "Iterations: 82\n",
      "SE_train: 482646.9905010503. RMSE_train: 0.7766479703775937\n",
      "SE_test:  157187.30602143824. RMSE_test:  0.8864375432529878\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 482254.09034149104. RMSE_train: 0.7763317897695703\n",
      "SE_test:  157143.07230563587. RMSE_test:  0.8863128093088979\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 481872.0273887771. RMSE_train: 0.7760242067013118\n",
      "SE_test:  157100.43070226055. RMSE_test:  0.8861925483169204\n",
      "\n",
      "Iterations: 85\n",
      "SE_train: 481500.42089347186. RMSE_train: 0.775724924695277\n",
      "SE_test:  157059.3197452743. RMSE_test:  0.8860765887128199\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 481138.9065760151. RMSE_train: 0.7754336598151104\n",
      "SE_test:  157019.6804894399. RMSE_test:  0.8859647658898495\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 480787.13573331607. RMSE_train: 0.7751501399995625\n",
      "SE_test:  156981.45639972482. RMSE_test:  0.8858569218990999\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 480444.77440161724. RMSE_train: 0.7748741044374232\n",
      "SE_test:  156944.5932464399. RMSE_test:  0.8857529051650397\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 480111.50257252605. RMSE_train: 0.7746053029813456\n",
      "SE_test:  156909.03900578668. RMSE_test:  0.8856525702154069\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 479787.0134591878. RMSE_train: 0.7743434955984702\n",
      "SE_test:  156874.7437653916. RMSE_test:  0.8855557774243376\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 479471.01280967426. RMSE_train: 0.7740884518558073\n",
      "SE_test:  156841.65963456273. RMSE_test:  0.885462392768051\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 479163.21826419194. RMSE_train: 0.7738399504379263\n",
      "SE_test:  156809.7406589324. RMSE_test:  0.8853722875922074\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 478863.35875370016. RMSE_train: 0.7735977786952679\n",
      "SE_test:  156778.9427392845. RMSE_test:  0.8852853383904226\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 478571.1739366146. RMSE_train: 0.7733617322206388\n",
      "SE_test:  156749.2235541967. RMSE_test:  0.8852014265929528\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 478286.41367105395. RMSE_train: 0.7731316144520489\n",
      "SE_test:  156720.54248642278. RMSE_test:  0.8851204383653828\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 478008.8375202526. RMSE_train: 0.772907236300173\n",
      "SE_test:  156692.86055270463. RMSE_test:  0.8850422644164879\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 477738.21428864566. RMSE_train: 0.7726884157985974\n",
      "SE_test:  156666.1403368382. RMSE_test:  0.8849667998148113\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 477474.3215861435. RMSE_train: 0.7724749777750143\n",
      "SE_test:  156640.34592579072. RMSE_test:  0.8848939438134246\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 477216.94541916583. RMSE_train: 0.7722667535423532\n",
      "SE_test:  156615.4428487215. RMSE_test:  0.8848235996824853\n",
      "\n",
      "Iterations: 0\n",
      "SE_train: 6248499.781066651. RMSE_train: 2.794456090103585\n",
      "SE_test:  325481.3115793353. RMSE_test:  1.2755645315988835\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 929118.9560285442. RMSE_train: 1.077568954877901\n",
      "SE_test:  225175.9735505466. RMSE_test:  1.0609634690324556\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 753208.4460179877. RMSE_train: 0.970212802336324\n",
      "SE_test:  205238.5903701732. RMSE_test:  1.0129054726757996\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 3\n",
      "SE_train: 706286.4488928383. RMSE_train: 0.9395066257611383\n",
      "SE_test:  196982.8292704261. RMSE_test:  0.9923242201049972\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 683889.2105744611. RMSE_train: 0.9244901459679157\n",
      "SE_test:  192228.1541277251. RMSE_test:  0.9802749478866631\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 669445.6727377038. RMSE_train: 0.9146755699855992\n",
      "SE_test:  188858.63173252204. RMSE_test:  0.971645459380054\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 658115.8671756715. RMSE_train: 0.9069024836361823\n",
      "SE_test:  186117.00211820196. RMSE_test:  0.9645670680512415\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 648183.5022239055. RMSE_train: 0.9000329245834076\n",
      "SE_test:  183725.57918922225. RMSE_test:  0.958350157609914\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 639124.1886795032. RMSE_train: 0.8937211539256382\n",
      "SE_test:  181603.1598270684. RMSE_test:  0.9527985914413459\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 630830.3645088245. RMSE_train: 0.8879033716754148\n",
      "SE_test:  179724.80050950125. RMSE_test:  0.9478582864162604\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 623253.0929692243. RMSE_train: 0.8825546989417933\n",
      "SE_test:  178067.14070662178. RMSE_test:  0.9434769590673255\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 616314.5538955516. RMSE_train: 0.8776283061559994\n",
      "SE_test:  176601.63784913195. RMSE_test:  0.9395865029141295\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 609923.561570654. RMSE_train: 0.8730660803417931\n",
      "SE_test:  175299.37477339752. RMSE_test:  0.9361158305300002\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 603995.9494044406. RMSE_train: 0.8688132256746085\n",
      "SE_test:  174134.40463321176. RMSE_test:  0.9330001181295576\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 598461.830101674. RMSE_train: 0.8648238111777292\n",
      "SE_test:  173084.76349619962. RMSE_test:  0.9301839154901058\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 593265.3991129735. RMSE_train: 0.8610610021484183\n",
      "SE_test:  172132.3263551297. RMSE_test:  0.9276211138068089\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 588362.494958207. RMSE_train: 0.8574956011371168\n",
      "SE_test:  171262.2824180825. RMSE_test:  0.9252738105281475\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 583718.0984002432. RMSE_train: 0.8541044603385339\n",
      "SE_test:  170462.5615269674. RMSE_test:  0.9231109681529825\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 579304.3195172376. RMSE_train: 0.8508691814492517\n",
      "SE_test:  169723.3203938552. RMSE_test:  0.9211071761195856\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 575098.8482884563. RMSE_train: 0.8477751049709839\n",
      "SE_test:  169036.51130286884. RMSE_test:  0.9192415925327799\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 571083.7400700179. RMSE_train: 0.8448105095701257\n",
      "SE_test:  168395.5295137319. RMSE_test:  0.9174970677806488\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 567244.4423398322. RMSE_train: 0.8419659628045902\n",
      "SE_test:  167794.92940118868. RMSE_test:  0.915859432075188\n",
      "\n",
      "Iterations: 22\n",
      "SE_train: 563569.0124220641. RMSE_train: 0.8392337932435981\n",
      "SE_test:  167230.19838071943. RMSE_test:  0.9143169237533637\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 560047.4974696139. RMSE_train: 0.8366076680470171\n",
      "SE_test:  166697.5778857756. RMSE_test:  0.9128597338699942\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 556671.4532611602. RMSE_train: 0.8340822627295464\n",
      "SE_test:  166193.9215071699. RMSE_test:  0.9114796435227354\n",
      "\n",
      "Iterations: 25\n",
      "SE_train: 553433.5778188794. RMSE_train: 0.8316530084482605\n",
      "SE_test:  165716.5818026659. RMSE_test:  0.9101697331461155\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 550327.4357270628. RMSE_train: 0.8293159012326851\n",
      "SE_test:  165263.3189892524. RMSE_test:  0.9089241469419955\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 547347.2512105823. RMSE_train: 0.8270673585180155\n",
      "SE_test:  164832.22642522914. RMSE_test:  0.9077378997410399\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 544487.7520063929. RMSE_train: 0.8249041107799591\n",
      "SE_test:  164421.66924453448. RMSE_test:  0.9066067172249122\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 541744.0506189456. RMSE_train: 0.8228231190953286\n",
      "SE_test:  164030.23361516595. RMSE_test:  0.9055269032401007\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 539111.5536616117. RMSE_train: 0.8208215122707636\n",
      "SE_test:  163656.68485426687. RMSE_test:  0.9044952298552823\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 536585.8931063756. RMSE_train: 0.818896539349823\n",
      "SE_test:  163299.93309971492. RMSE_test:  0.9035088469787638\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 534162.8752934794. RMSE_train: 0.8170455347173932\n",
      "SE_test:  162959.00549299532. RMSE_test:  0.9025652089650505\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 531838.4446810747. RMSE_train: 0.8152658937862257\n",
      "SE_test:  162633.02395371653. RMSE_test:  0.9016620159164319\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 529608.6598365521. RMSE_train: 0.8135550575781769\n",
      "SE_test:  162321.1876915019. RMSE_test:  0.9007971675103894\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 527469.6793743802. RMSE_train: 0.811910504611069\n",
      "SE_test:  162022.75965100087. RMSE_test:  0.899968727276614\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 525417.7556426086. RMSE_train: 0.8103297485283243\n",
      "SE_test:  161737.05614654394. RMSE_test:  0.8991748953787017\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 523449.23407701694. RMSE_train: 0.8088103399570301\n",
      "SE_test:  161463.43901956044. RMSE_test:  0.8984139881380103\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 521560.5563281164. RMSE_train: 0.8073498711891262\n",
      "SE_test:  161201.30974146718. RMSE_test:  0.8976844227619933\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 519748.2655271395. RMSE_train: 0.8059459824543648\n",
      "SE_test:  160950.10497939776. RMSE_test:  0.8969847059837794\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 518009.0123598888. RMSE_train: 0.8045963687672024\n",
      "SE_test:  160709.29323450863. RMSE_test:  0.8963134255625127\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 516339.56094095676. RMSE_train: 0.8032987865661763\n",
      "SE_test:  160478.37224670802. RMSE_test:  0.8956692438175673\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 514736.79378670384. RMSE_train: 0.8020510595927912\n",
      "SE_test:  160256.86693318817. RMSE_test:  0.8950508925669428\n",
      "\n",
      "Iterations: 43\n",
      "SE_train: 513197.7154586094. RMSE_train: 0.8008510836647712\n",
      "SE_test:  160044.3276893367. RMSE_test:  0.8944571690052994\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 511719.4546753624. RMSE_train: 0.7996968301737623\n",
      "SE_test:  159840.3289303077. RMSE_test:  0.8938869321919604\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 510299.2648675578. RMSE_train: 0.7985863482753511\n",
      "SE_test:  159644.4677902621. RMSE_test:  0.8933390999247403\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 508934.5232759893. RMSE_train: 0.7975177658408319\n",
      "SE_test:  159456.36292555576. RMSE_test:  0.8928126458554745\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 507622.7287758682. RMSE_train: 0.7964892893067422\n",
      "SE_test:  159275.6533891436. RMSE_test:  0.8923065967606467\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 506361.4986551853. RMSE_train: 0.7954992025972758\n",
      "SE_test:  159101.99755849448. RMSE_test:  0.8918200299217667\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 505148.5645890873. RMSE_train: 0.7945458653083676\n",
      "SE_test:  158935.0721080855. RMSE_test:  0.8913520705941842\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 503981.76804693835. RMSE_train: 0.7936277103407633\n",
      "SE_test:  158774.57102352852. RMSE_test:  0.8909018895594005\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 502859.05534602905. RMSE_train: 0.7927432411536496\n",
      "SE_test:  158620.20465682325. RMSE_test:  0.8904687007624907\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 501778.4725365107. RMSE_train: 0.7918910287888911\n",
      "SE_test:  158471.69882330077. RMSE_test:  0.8900517590389968\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 500738.1602672986. RMSE_train: 0.7910697087895913\n",
      "SE_test:  158328.79394081127. RMSE_test:  0.8896503579354014\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 499736.3487484321. RMSE_train: 0.7902779781103457\n",
      "SE_test:  158191.2442110368. RMSE_test:  0.8892638276251925\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 498771.3528941285. RMSE_train: 0.789514592092207\n",
      "SE_test:  158058.81684221563. RMSE_test:  0.8888915329206627\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 497841.5677013262. RMSE_train: 0.7887783615521478\n",
      "SE_test:  157931.2913119456. RMSE_test:  0.88853287137865\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 496945.4638961234. RMSE_train: 0.7880681500189236\n",
      "SE_test:  157808.45866841124. RMSE_test:  0.8881872714973537\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 496081.5838618305. RMSE_train: 0.7873828711321323\n",
      "SE_test:  157690.12086807052. RMSE_test:  0.8878541910003086\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 495248.537847467. RMSE_train: 0.7867214862090602\n",
      "SE_test:  157576.09014785205. RMSE_test:  0.8875331152035049\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 494445.0004468841. RMSE_train: 0.7860830019766016\n",
      "SE_test:  157466.18843011587. RMSE_test:  0.8872235554620562\n",
      "\n",
      "Iterations: 61\n",
      "SE_train: 493669.70733132004. RMSE_train: 0.7854664684592236\n",
      "SE_test:  157360.24675863568. RMSE_test:  0.8869250476927186\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 492921.45221510954. RMSE_train: 0.7848709770110438\n",
      "SE_test:  157258.10476421492. RMSE_test:  0.8866371509694391\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 492199.08403207856. RMSE_train: 0.7842956584779223\n",
      "SE_test:  157159.6101586437. RMSE_test:  0.8863594461892818\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 64\n",
      "SE_train: 491501.5043010583. RMSE_train: 0.7837396814757919\n",
      "SE_test:  157064.61825594326. RMSE_test:  0.8860915348066613\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 490827.6646595295. RMSE_train: 0.7832022507715571\n",
      "SE_test:  156972.9915199265. RMSE_test:  0.8858330376339629\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 490176.56454585365. RMSE_train: 0.7826826057537204\n",
      "SE_test:  156884.5991371358. RMSE_test:  0.8855835937066451\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 489547.24901379796. RMSE_train: 0.7821800189822081\n",
      "SE_test:  156799.31661445403. RMSE_test:  0.885342859211512\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 488938.80666383024. RMSE_train: 0.7816937948072323\n",
      "SE_test:  156717.02540045403. RMSE_test:  0.8851105064761396\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 488350.36767942604. RMSE_train: 0.7812232680498121\n",
      "SE_test:  156637.61252966756. RMSE_test:  0.884886223017696\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 487781.1019570947. RMSE_train: 0.7807678027367627\n",
      "SE_test:  156560.97028897813. RMSE_test:  0.8846697106494227\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 487230.2173222982. RMSE_train: 0.7803267908855573\n",
      "SE_test:  156486.99590518672. RMSE_test:  0.8844606846425517\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 486696.9578237071. RMSE_train: 0.7798996513345432\n",
      "SE_test:  156415.59125286716. RMSE_test:  0.884258872941582\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 486180.6021004065. RMSE_train: 0.7794858286155917\n",
      "SE_test:  156346.6625815821. RMSE_test:  0.8840640154306705\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 485680.4618171417. RMSE_train: 0.77908479186653\n",
      "SE_test:  156280.12026142434. RMSE_test:  0.8838758632485552\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 485195.8801643671. RMSE_train: 0.7786960337819393\n",
      "SE_test:  156215.87854599947. RMSE_test:  0.8836941781498242\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 484726.23041981744. RMSE_train: 0.7783190696007711\n",
      "SE_test:  156153.85535181136. RMSE_test:  0.8835187319098748\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 484270.9145689282. RMSE_train: 0.7779534361296409\n",
      "SE_test:  156093.97205307923. RMSE_test:  0.883349305771072\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 483829.3619822813. RMSE_train: 0.7775986908012545\n",
      "SE_test:  156036.15329104252. RMSE_test:  0.8831856899276647\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 483401.02814797463. RMSE_train: 0.7772544107671351\n",
      "SE_test:  155980.32679681142. RMSE_test:  0.8830276830470047\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 482985.3934571012. RMSE_train: 0.7769201920239773\n",
      "SE_test:  155926.42322678142. RMSE_test:  0.8828750918244759\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 482581.9620407043. RMSE_train: 0.7765956485730461\n",
      "SE_test:  155874.3760098521. RMSE_test:  0.8827277305701536\n",
      "\n",
      "Iterations: 82\n",
      "SE_train: 482190.2606569113. RMSE_train: 0.7762804116122434\n",
      "SE_test:  155824.12120543743. RMSE_test:  0.882585420824481\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 481809.8376259214. RMSE_train: 0.7759741287595971\n",
      "SE_test:  155775.5973715589. RMSE_test:  0.8824479910010912\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 481440.2618121709. RMSE_train: 0.7756764633081954\n",
      "SE_test:  155728.74544219155. RMSE_test:  0.8823152760545532\n",
      "\n",
      "Iterations: 85\n",
      "SE_train: 481081.12165116286. RMSE_train: 0.7753870935110727\n",
      "SE_test:  155683.5086131337. RMSE_test:  0.8821871171710857\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 480732.02422010724. RMSE_train: 0.7751057118958453\n",
      "SE_test:  155639.8322356794. RMSE_test:  0.8820633614803005\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 480392.5943500759. RMSE_train: 0.7748320246076951\n",
      "SE_test:  155597.6637174723. RMSE_test:  0.8819438617863041\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 480062.47377883765. RMSE_train: 0.7745657507804408\n",
      "SE_test:  155556.95242988862. RMSE_test:  0.8818284763163969\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 479741.32034163526. RMSE_train: 0.7743066219338708\n",
      "SE_test:  155517.64962134077. RMSE_test:  0.8817170684857152\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 479428.80719972827. RMSE_train: 0.774054381397544\n",
      "SE_test:  155479.70833612297. RMSE_test:  0.8816095066768165\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 479124.62210393994. RMSE_train: 0.7738087837591546\n",
      "SE_test:  155443.08333807578. RMSE_test:  0.8815056640322158\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 478828.4666923383. RMSE_train: 0.7735695943370535\n",
      "SE_test:  155407.7310388111. RMSE_test:  0.8814054182591997\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 478540.0558203968. RMSE_train: 0.7733365886758657\n",
      "SE_test:  155373.60943002504. RMSE_test:  0.8813086514456281\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 478259.1169222851. RMSE_train: 0.7731095520643648\n",
      "SE_test:  155340.67801946608. RMSE_test:  0.8812152498855418\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 477985.3894019029. RMSE_train: 0.772888279074714\n",
      "SE_test:  155308.89777029832. RMSE_test:  0.881125103913885\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 477718.6240523453. RMSE_train: 0.77267257312223\n",
      "SE_test:  155278.23104356756. RMSE_test:  0.8810381077495476\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 477458.58250272874. RMSE_train: 0.7724622460449976\n",
      "SE_test:  155248.64154340565. RMSE_test:  0.8809541593457323\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 477205.036690872. RMSE_train: 0.7722571177022994\n",
      "SE_test:  155220.0942648051. RMSE_test:  0.8808731602472017\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 476957.76836117264. RMSE_train: 0.7720570155914962\n",
      "SE_test:  155192.5554437648. RMSE_test:  0.8807950154538693\n",
      "\n",
      "Iterations: 0\n",
      "SE_train: 5926125.3216556. RMSE_train: 2.7214153249332664\n",
      "SE_test:  322198.6833888528. RMSE_test:  1.2691159046188805\n",
      "\n",
      "Iterations: 1\n",
      "SE_train: 919179.4455523166. RMSE_train: 1.071789658932697\n",
      "SE_test:  226332.47445128422. RMSE_test:  1.0636845270351918\n",
      "\n",
      "Iterations: 2\n",
      "SE_train: 751225.7492259657. RMSE_train: 0.9689349984265767\n",
      "SE_test:  206566.33943591296. RMSE_test:  1.0161765831101757\n",
      "\n",
      "Iterations: 3\n",
      "SE_train: 705864.2821882055. RMSE_train: 0.9392257994027748\n",
      "SE_test:  198401.39801057975. RMSE_test:  0.9958909138672322\n",
      "\n",
      "Iterations: 4\n",
      "SE_train: 684365.6510966697. RMSE_train: 0.924812119084282\n",
      "SE_test:  193781.74256225798. RMSE_test:  0.9842282685949955\n",
      "\n",
      "Iterations: 5\n",
      "SE_train: 670689.8352665293. RMSE_train: 0.9155251361734527\n",
      "SE_test:  190596.74470846073. RMSE_test:  0.9761063666312797\n",
      "\n",
      "Iterations: 6\n",
      "SE_train: 660087.6295564562. RMSE_train: 0.9082600400339665\n",
      "SE_test:  188067.89356430885. RMSE_test:  0.969609219218529\n",
      "\n",
      "Iterations: 7\n",
      "SE_train: 650801.5061839492. RMSE_train: 0.9018487030552652\n",
      "SE_test:  185886.29678995098. RMSE_test:  0.9639690577593496\n",
      "\n",
      "Iterations: 8\n",
      "SE_train: 642255.4244250514. RMSE_train: 0.8959077652745843\n",
      "SE_test:  183950.76284088977. RMSE_test:  0.958937279730063\n",
      "\n",
      "Iterations: 9\n",
      "SE_train: 634343.2830560686. RMSE_train: 0.8903721826680768\n",
      "SE_test:  182234.0983454124. RMSE_test:  0.9544522963972487\n",
      "\n",
      "Iterations: 10\n",
      "SE_train: 627051.1129816921. RMSE_train: 0.8852396991035211\n",
      "SE_test:  180717.95901957096. RMSE_test:  0.950473608829213\n",
      "\n",
      "Iterations: 11\n",
      "SE_train: 620329.8033622514. RMSE_train: 0.8804825107961728\n",
      "SE_test:  179377.13058639373. RMSE_test:  0.9469410469977558\n",
      "\n",
      "Iterations: 12\n",
      "SE_train: 614098.1811011793. RMSE_train: 0.876048833940774\n",
      "SE_test:  178182.5534432015. RMSE_test:  0.9437826629133935\n",
      "\n",
      "Iterations: 13\n",
      "SE_train: 608269.1522808259. RMSE_train: 0.8718811864138116\n",
      "SE_test:  177106.1858583353. RMSE_test:  0.9409277373104908\n",
      "\n",
      "Iterations: 14\n",
      "SE_train: 602766.0277823668. RMSE_train: 0.867928189348731\n",
      "SE_test:  176123.89422546283. RMSE_test:  0.9383147552210518\n",
      "\n",
      "Iterations: 15\n",
      "SE_train: 597529.286361247. RMSE_train: 0.864149749433381\n",
      "SE_test:  175216.57270356675. RMSE_test:  0.9358947188352105\n",
      "\n",
      "Iterations: 16\n",
      "SE_train: 592517.703618456. RMSE_train: 0.8605182312313615\n",
      "SE_test:  174370.12064233285. RMSE_test:  0.9336313796277035\n",
      "\n",
      "Iterations: 17\n",
      "SE_train: 587706.1216287755. RMSE_train: 0.857017159437044\n",
      "SE_test:  173574.74123083593. RMSE_test:  0.9314995925608781\n",
      "\n",
      "Iterations: 18\n",
      "SE_train: 583081.3570318505. RMSE_train: 0.8536384888049529\n",
      "SE_test:  172823.91873750061. RMSE_test:  0.9294827414602715\n",
      "\n",
      "Iterations: 19\n",
      "SE_train: 578637.6264344079. RMSE_train: 0.8503794285827785\n",
      "SE_test:  172113.37009921035. RMSE_test:  0.9275700347685223\n",
      "\n",
      "Iterations: 20\n",
      "SE_train: 574372.625444629. RMSE_train: 0.8472396595103715\n",
      "SE_test:  171440.17215551052. RMSE_test:  0.9257542256946011\n",
      "\n",
      "Iterations: 21\n",
      "SE_train: 570284.8479377911. RMSE_train: 0.8442193977752508\n",
      "SE_test:  170802.14428422457. RMSE_test:  0.9240299869720624\n",
      "\n",
      "Iterations: 22\n",
      "SE_train: 566372.1501050247. RMSE_train: 0.8413183381791864\n",
      "SE_test:  170197.4688894254. RMSE_test:  0.9223929068598997\n",
      "\n",
      "Iterations: 23\n",
      "SE_train: 562631.2259929423. RMSE_train: 0.838535254358986\n",
      "SE_test:  169624.48714200544. RMSE_test:  0.9208389475868594\n",
      "\n",
      "Iterations: 24\n",
      "SE_train: 559057.6034664864. RMSE_train: 0.8358679815160873\n",
      "SE_test:  169081.60463003378. RMSE_test:  0.9193641959201878\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 25\n",
      "SE_train: 555645.8661981164. RMSE_train: 0.8333135702311081\n",
      "SE_test:  168567.2576737984. RMSE_test:  0.9179647759634958\n",
      "\n",
      "Iterations: 26\n",
      "SE_train: 552389.9317926922. RMSE_train: 0.8308684870831673\n",
      "SE_test:  168079.9092112785. RMSE_test:  0.9166368415057073\n",
      "\n",
      "Iterations: 27\n",
      "SE_train: 549283.3084283146. RMSE_train: 0.8285288039288773\n",
      "SE_test:  167618.05678207273. RMSE_test:  0.9153766011335247\n",
      "\n",
      "Iterations: 28\n",
      "SE_train: 546319.3043715304. RMSE_train: 0.8262903555993766\n",
      "SE_test:  167180.24365683986. RMSE_test:  0.914180351945864\n",
      "\n",
      "Iterations: 29\n",
      "SE_train: 543491.1884032692. RMSE_train: 0.8241488633862163\n",
      "SE_test:  166765.0689720636. RMSE_test:  0.9130445105808778\n",
      "\n",
      "Iterations: 30\n",
      "SE_train: 540792.3076519931. RMSE_train: 0.8221000282138116\n",
      "SE_test:  166371.19528672943. RMSE_test:  0.9119656371573122\n",
      "\n",
      "Iterations: 31\n",
      "SE_train: 538216.1710753355. RMSE_train: 0.8201395989477641\n",
      "SE_test:  165997.3532636578. RMSE_test:  0.9109404512327322\n",
      "\n",
      "Iterations: 32\n",
      "SE_train: 535756.5061714987. RMSE_train: 0.8182634210074895\n",
      "SE_test:  165642.34377180366. RMSE_test:  0.9099658405206902\n",
      "\n",
      "Iterations: 33\n",
      "SE_train: 533407.2952282723. RMSE_train: 0.8164674696632112\n",
      "SE_test:  165305.03792628623. RMSE_test:  0.9090388637367032\n",
      "\n",
      "Iterations: 34\n",
      "SE_train: 531162.7961677539. RMSE_train: 0.8147478715835347\n",
      "SE_test:  164984.37561231447. RMSE_test:  0.9081567490464387\n",
      "\n",
      "Iterations: 35\n",
      "SE_train: 529017.5519706833. RMSE_train: 0.8131009174831446\n",
      "SE_test:  164679.36297884036. RMSE_test:  0.9073168894422994\n",
      "\n",
      "Iterations: 36\n",
      "SE_train: 526966.3917900553. RMSE_train: 0.8115230681272391\n",
      "SE_test:  164389.06929725513. RMSE_test:  0.906516836139127\n",
      "\n",
      "Iterations: 37\n",
      "SE_train: 525004.4261609555. RMSE_train: 0.8100109554654923\n",
      "SE_test:  164112.62348631982. RMSE_test:  0.9057542908295684\n",
      "\n",
      "Iterations: 38\n",
      "SE_train: 523127.0381594113. RMSE_train: 0.8085613802817141\n",
      "SE_test:  163849.21052120748. RMSE_test:  0.9050270974154064\n",
      "\n",
      "Iterations: 39\n",
      "SE_train: 521329.87192482763. RMSE_train: 0.8071713074353731\n",
      "SE_test:  163598.0678750692. RMSE_test:  0.904333233642266\n",
      "\n",
      "Iterations: 40\n",
      "SE_train: 519608.8196168212. RMSE_train: 0.8058378595246685\n",
      "SE_test:  163358.4820866691. RMSE_test:  0.9036708029145\n",
      "\n",
      "Iterations: 41\n",
      "SE_train: 517960.007605107. RMSE_train: 0.8045583096028144\n",
      "SE_test:  163129.78550585566. RMSE_test:  0.9030380264513022\n",
      "\n",
      "Iterations: 42\n",
      "SE_train: 516379.78247529664. RMSE_train: 0.8033300734198117\n",
      "SE_test:  162911.35323949085. RMSE_test:  0.9024332358634428\n",
      "\n",
      "Iterations: 43\n",
      "SE_train: 514864.6972649845. RMSE_train: 0.8021507015356628\n",
      "SE_test:  162702.6003005633. RMSE_test:  0.901854866173539\n",
      "\n",
      "Iterations: 44\n",
      "SE_train: 513411.4982101496. RMSE_train: 0.801017871548615\n",
      "SE_test:  162502.9789521095. RMSE_test:  0.90130144927046\n",
      "\n",
      "Iterations: 45\n",
      "SE_train: 512017.11218160274. RMSE_train: 0.7999293806043588\n",
      "SE_test:  162311.9762320305. RMSE_test:  0.9007716077715734\n",
      "\n",
      "Iterations: 46\n",
      "SE_train: 510678.6349138057. RMSE_train: 0.7988831382911029\n",
      "SE_test:  162129.11164342854. RMSE_test:  0.9002640492610379\n",
      "\n",
      "Iterations: 47\n",
      "SE_train: 509393.320072987. RMSE_train: 0.7978771599808618\n",
      "SE_test:  161953.93499626566. RMSE_test:  0.8997775608743125\n",
      "\n",
      "Iterations: 48\n",
      "SE_train: 508158.5691695431. RMSE_train: 0.7969095606427882\n",
      "SE_test:  161786.02438793477. RMSE_test:  0.8993110042028815\n",
      "\n",
      "Iterations: 49\n",
      "SE_train: 506971.92229257926. RMSE_train: 0.795978549131245\n",
      "SE_test:  161624.98431299647. RMSE_test:  0.8988633104995889\n",
      "\n",
      "Iterations: 50\n",
      "SE_train: 505831.04962407774. RMSE_train: 0.7950824229334045\n",
      "SE_test:  161470.44389416283. RMSE_test:  0.8984334761692058\n",
      "\n",
      "Iterations: 51\n",
      "SE_train: 504733.7436772009. RMSE_train: 0.7942195633490728\n",
      "SE_test:  161322.055228344. RMSE_test:  0.8980205585329185\n",
      "\n",
      "Iterations: 52\n",
      "SE_train: 503677.9121962403. RMSE_train: 0.7933884310681397\n",
      "SE_test:  161179.49184258605. RMSE_test:  0.8976236718575952\n",
      "\n",
      "Iterations: 53\n",
      "SE_train: 502661.571651451. RMSE_train: 0.7925875621060153\n",
      "SE_test:  161042.44725541296. RMSE_test:  0.897241983642011\n",
      "\n",
      "Iterations: 54\n",
      "SE_train: 501682.8412623528. RMSE_train: 0.7918155640561569\n",
      "SE_test:  160910.6336390683. RMSE_test:  0.8968747111516557\n",
      "\n",
      "Iterations: 55\n",
      "SE_train: 500739.9374852448. RMSE_train: 0.7910711126191247\n",
      "SE_test:  160783.7805783319. RMSE_test:  0.8965211181937838\n",
      "\n",
      "Iterations: 56\n",
      "SE_train: 499831.16890467907. RMSE_train: 0.7903529483695367\n",
      "SE_test:  160661.63392126493. RMSE_test:  0.8961805121230654\n",
      "\n",
      "Iterations: 57\n",
      "SE_train: 498954.93147494923. RMSE_train: 0.7896598737262076\n",
      "SE_test:  160543.95471690825. RMSE_test:  0.8958522410669062\n",
      "\n",
      "Iterations: 58\n",
      "SE_train: 498109.7040639947. RMSE_train: 0.7889907500948341\n",
      "SE_test:  160430.5182347975. RMSE_test:  0.8955356913587214\n",
      "\n",
      "Iterations: 59\n",
      "SE_train: 497294.0442590477. RMSE_train: 0.7883444951572696\n",
      "SE_test:  160321.11306093176. RMSE_test:  0.8952302851665197\n",
      "\n",
      "Iterations: 60\n",
      "SE_train: 496506.5844003166. RMSE_train: 0.7877200802862458\n",
      "SE_test:  160215.5402644973. RMSE_test:  0.8949354783029435\n",
      "\n",
      "Iterations: 61\n",
      "SE_train: 495746.02781565365. RMSE_train: 0.787116528069083\n",
      "SE_test:  160113.61262986963. RMSE_test:  0.8946507582032923\n",
      "\n",
      "Iterations: 62\n",
      "SE_train: 495011.14523449924. RMSE_train: 0.7865329099276522\n",
      "SE_test:  160015.15394821676. RMSE_test:  0.8943756420572799\n",
      "\n",
      "Iterations: 63\n",
      "SE_train: 494300.77136466047. RMSE_train: 0.7859683438255968\n",
      "SE_test:  159919.99836331396. RMSE_test:  0.8941096750808842\n",
      "\n",
      "Iterations: 64\n",
      "SE_train: 493613.8016200311. RMSE_train: 0.7854219920570479\n",
      "SE_test:  159827.9897661157. RMSE_test:  0.8938524289143016\n",
      "\n",
      "Iterations: 65\n",
      "SE_train: 492949.1889893515. RMSE_train: 0.7848930591123217\n",
      "SE_test:  159738.9812333807. RMSE_test:  0.893603500133957\n",
      "\n",
      "Iterations: 66\n",
      "SE_train: 492305.94104046846. RMSE_train: 0.7843807896192573\n",
      "SE_test:  159652.83450528604. RMSE_test:  0.8933625088653869\n",
      "\n",
      "Iterations: 67\n",
      "SE_train: 491683.11705423536. RMSE_train: 0.7838844663583459\n",
      "SE_test:  159569.4194980012. RMSE_test:  0.8931290974865855\n",
      "\n",
      "Iterations: 68\n",
      "SE_train: 491079.82528537017. RMSE_train: 0.7834034083520871\n",
      "SE_test:  159488.61384704587. RMSE_test:  0.8929029294108883\n",
      "\n",
      "Iterations: 69\n",
      "SE_train: 490495.2203466495. RMSE_train: 0.7829369690280584\n",
      "SE_test:  159410.30247802477. RMSE_test:  0.8926836879405345\n",
      "\n",
      "Iterations: 70\n",
      "SE_train: 489928.50071453355. RMSE_train: 0.7824845344563479\n",
      "SE_test:  159334.3772014419. RMSE_test:  0.8924710751822726\n",
      "\n",
      "Iterations: 71\n",
      "SE_train: 489378.90635318926. RMSE_train: 0.7820455216609307\n",
      "SE_test:  159260.73632892495. RMSE_test:  0.8922648110180624\n",
      "\n",
      "Iterations: 72\n",
      "SE_train: 488845.71645477135. RMSE_train: 0.7816193770051105\n",
      "SE_test:  159189.2843084045. RMSE_test:  0.8920646321244701\n",
      "\n",
      "Iterations: 73\n",
      "SE_train: 488328.2472930224. RMSE_train: 0.7812055746503647\n",
      "SE_test:  159119.93137625075. RMSE_test:  0.8918702910355782\n",
      "\n",
      "Iterations: 74\n",
      "SE_train: 487825.85018696176. RMSE_train: 0.7808036150875469\n",
      "SE_test:  159052.59322466698. RMSE_test:  0.8916815552450227\n",
      "\n",
      "Iterations: 75\n",
      "SE_train: 487337.9095714099. RMSE_train: 0.7804130237392645\n",
      "SE_test:  158987.19068288823. RMSE_test:  0.8914982063434224\n",
      "\n",
      "Iterations: 76\n",
      "SE_train: 486863.84117082745. RMSE_train: 0.7800333496318996\n",
      "SE_test:  158923.64941118404. RMSE_test:  0.8913200391887001\n",
      "\n",
      "Iterations: 77\n",
      "SE_train: 486403.090271914. RMSE_train: 0.7796641641348132\n",
      "SE_test:  158861.89960662407. RMSE_test:  0.8911468611066459\n",
      "\n",
      "Iterations: 78\n",
      "SE_train: 485955.1300915872. RMSE_train: 0.7793050597651007\n",
      "SE_test:  158801.87572010246. RMSE_test:  0.8909784911205589\n",
      "\n",
      "Iterations: 79\n",
      "SE_train: 485519.46023542975. RMSE_train: 0.7789556490549486\n",
      "SE_test:  158743.51618403764. RMSE_test:  0.8908147592085524\n",
      "\n",
      "Iterations: 80\n",
      "SE_train: 485095.6052424556. RMSE_train: 0.7786155634791628\n",
      "SE_test:  158686.76315041067. RMSE_test:  0.8906555055877835\n",
      "\n",
      "Iterations: 81\n",
      "SE_train: 484683.11321175925. RMSE_train: 0.7782844524401268\n",
      "SE_test:  158631.56223901754. RMSE_test:  0.8905005800254441\n",
      "\n",
      "Iterations: 82\n",
      "SE_train: 484281.55450645083. RMSE_train: 0.777961982307247\n",
      "SE_test:  158577.86229570385. RMSE_test:  0.8903498411760323\n",
      "\n",
      "Iterations: 83\n",
      "SE_train: 483890.5205310761. RMSE_train: 0.7776478355085098\n",
      "SE_test:  158525.61516066358. RMSE_test:  0.8902031559452923\n",
      "\n",
      "Iterations: 84\n",
      "SE_train: 483509.6225776574. RMSE_train: 0.7773417096708609\n",
      "SE_test:  158474.7754466952. RMSE_test:  0.8900603988806649\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 85\n",
      "SE_train: 483138.4907366727. RMSE_train: 0.7770433168070104\n",
      "SE_test:  158425.30032761773. RMSE_test:  0.8899214515889529\n",
      "\n",
      "Iterations: 86\n",
      "SE_train: 482776.7728691924. RMSE_train: 0.7767523825461332\n",
      "SE_test:  158377.14933673156. RMSE_test:  0.8897862021809978\n",
      "\n",
      "Iterations: 87\n",
      "SE_train: 482424.1336364403. RMSE_train: 0.7764686454059286\n",
      "SE_test:  158330.2841756046. RMSE_test:  0.8896545447442712\n",
      "\n",
      "Iterations: 88\n",
      "SE_train: 482080.2535830887. RMSE_train: 0.7761918561034957\n",
      "SE_test:  158284.66853301736. RMSE_test:  0.889526378843016\n",
      "\n",
      "Iterations: 89\n",
      "SE_train: 481744.8282715556. RMSE_train: 0.7759217769032077\n",
      "SE_test:  158240.2679143492. RMSE_test:  0.8894016090468294\n",
      "\n",
      "Iterations: 90\n",
      "SE_train: 481417.56746385846. RMSE_train: 0.7756581809991663\n",
      "SE_test:  158197.04948122223. RMSE_test:  0.8892801444872597\n",
      "\n",
      "Iterations: 91\n",
      "SE_train: 481098.1943485557. RMSE_train: 0.7754008519305663\n",
      "SE_test:  158154.98190150558. RMSE_test:  0.889161898442788\n",
      "\n",
      "Iterations: 92\n",
      "SE_train: 480786.4448099818. RMSE_train: 0.7751495830280133\n",
      "SE_test:  158114.0352095668. RMSE_test:  0.8890467879519552\n",
      "\n",
      "Iterations: 93\n",
      "SE_train: 480482.066737527. RMSE_train: 0.7749041768892481\n",
      "SE_test:  158074.18067666798. RMSE_test:  0.888934733454413\n",
      "\n",
      "Iterations: 94\n",
      "SE_train: 480184.8193728308. RMSE_train: 0.7746644448828045\n",
      "SE_test:  158035.39069137265. RMSE_test:  0.8888256584595905\n",
      "\n",
      "Iterations: 95\n",
      "SE_train: 479894.4726924902. RMSE_train: 0.7744302066778901\n",
      "SE_test:  157997.63864979113. RMSE_test:  0.8887194892425495\n",
      "\n",
      "Iterations: 96\n",
      "SE_train: 479610.8068249582. RMSE_train: 0.7742012897996238\n",
      "SE_test:  157960.8988553201. RMSE_test:  0.888616154566114\n",
      "\n",
      "Iterations: 97\n",
      "SE_train: 479333.6114993343. RMSE_train: 0.7739775292079654\n",
      "SE_test:  157925.1464276858. RMSE_test:  0.888515585428789\n",
      "\n",
      "Iterations: 98\n",
      "SE_train: 479062.68552480167. RMSE_train: 0.773758766899502\n",
      "SE_test:  157890.3572209618. RMSE_test:  0.8884177148375876\n",
      "\n",
      "Iterations: 99\n",
      "SE_train: 478797.836298934. RMSE_train: 0.7735448515308134\n",
      "SE_test:  157856.50775009993. RMSE_test:  0.8883224776045093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "U_0,M_0,SE_0 = mat_fac(folded_data,X,0)\n",
    "U_1,M_0,SE_1 = mat_fac(folded_data,X,1)\n",
    "U_2,M_0,SE_2 = mat_fac(folded_data,X,2)\n",
    "U_3,M_0,SE_3 = mat_fac(folded_data,X,3)\n",
    "U_4,M_0,SE_4 = mat_fac(folded_data,X,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8884 0.8808 0.8848 0.8846 0.8853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.005, 0.05, 12, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
