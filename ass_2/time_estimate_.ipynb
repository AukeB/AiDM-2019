{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AiDM 2019 Group 26: Assignment 2: LSH for the Netflix data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Time estimation of the naïve algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auke Bruinsma, s1594443 and Simon van Wageningen, s2317079."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following text is taken from slide 2 of the instruction document.\n",
    "\n",
    "The data we import contains about **100.000** users that watches in total **17.700 movies**. Each user watches between **300 and 3000** movies. In total there are **65.000.000 (720 MB)** of the form:\n",
    "\n",
    "$$\\text{<user_id,movie_id>: \"user_id watched movie_id\"}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data.\n",
    "dataloc = 'data/user_movie.npy' # Location of the data file in string format.\n",
    "data = np.load(dataloc) # Import the data using numpy.load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact shape data: (65225506, 2)\n",
      "Max user_id: 103702\n",
      "Max movie_id: 17769\n",
      "\n",
      "First 10 records of the data:\n",
      "\n",
      "[[  0  29]\n",
      " [  0 156]\n",
      " [  0 172]\n",
      " [  0 174]\n",
      " [  0 190]\n",
      " [  0 196]\n",
      " [  0 240]\n",
      " [  0 294]\n",
      " [  0 298]\n",
      " [  0 328]]\n"
     ]
    }
   ],
   "source": [
    "# Some output to get an overview of the data.\n",
    "print('Exact shape data: {0}'.format(np.shape(data)))\n",
    "print('Max user_id: {0}'.format(np.max(data[:,0])))\n",
    "print('Max movie_id: {0}'.format(np.max(data[:,1])))\n",
    "print('\\nFirst 10 records of the data:\\n\\n{0}'.format(data[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Jaccard similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jaccard similarity between two sets $A$ and $B$ is defined as follows.\n",
    "\n",
    "$$ J(A,B) = \\frac{|A\\cap B|}{|A\\cup B|} $$\n",
    "\n",
    "We implemented this similirity in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsim(u1,u2):\n",
    "    u1_loc = np.where(data[:,0] == u1) # Make an array with the indices of the  ...\n",
    "    u2_loc = np.where(data[:,0] == u2) # elements of user u1 and user u2.\n",
    "    \n",
    "    u1_loc = np.reshape(u1_loc,len(u1_loc[0])) # Reshape the arrays since everything ...\n",
    "    u2_loc = np.reshape(u2_loc,len(u2_loc[0])) # was stored in the first element of a 2D-array.\n",
    "    \n",
    "    num_intersect = len(np.intersect1d(data[u1_loc][:,1],data[u2_loc][:,1],assume_unique=True)) # Find intersection\n",
    "    num_union = len(u1_loc)+len(u2_loc)-num_intersect # Compute the union of the two sets using the intersection.\n",
    "    jac_sim = num_intersect/num_union # Compute the Jaccard similarity\n",
    "    \n",
    "    return jac_sim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Naïve approache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_global(num_el):\n",
    "    jac_sim_arr = []\n",
    "    for i in range(num_el):\n",
    "        for j in range(num_el):\n",
    "            if i < j:\n",
    "                jac_sim_arr.append(jsim(i,j))\n",
    "    return np.mean(jac_sim_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23281175956200117\n",
      "CPU times: user 13.9 s, sys: 3.47 s, total: 17.4 s\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global_mean = R_global(10)\n",
    "print(global_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote down the computation times until we reached 10 users. The number of computations that will be done for $k$ users can be calculated as follows:\n",
    "\n",
    "$$ \\sum_{i=1}^{k-1} i $$\n",
    "\n",
    "Or:\n",
    "\n",
    "$$ \\frac{k^2-k}{2} $$\n",
    "\n",
    "For a large number of users it can be approximated by:\n",
    "\n",
    "$$ \\frac{k^2}{2} $$\n",
    "\n",
    "In the table, all the numbers are computed, except the last one, because that is our estimation for all users. The fourth column is the ratio between the second and third column. You can clearly see the computation time scales linearly with the computations (which makes sense). Therefore we estimate the computation time for all users to be 900.000.000 seconds, or approximately 28.5 years.\n",
    "\n",
    "|Number of users|Number of elements|Wall time (s)|Ratio|\n",
    "|---|---|---|---|\n",
    "|2|1|0.183|0.183|\n",
    "|3|3|0.530|0.177|\n",
    "|4|6|1.1|0.183|\n",
    "|5|10|1.78|0.178|\n",
    "|6|15|2.68|0.179|\n",
    "|7|21|3.72|0.178|\n",
    "|8|28|4.96|0.178|\n",
    "|9|36|6.47|0.180|\n",
    "|10|45|7.98|0.177|\n",
    "|$1 \\cdot 10^5$|$5 \\cdot 10^9$|$9 \\cdot 10^8$|0.180|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function jsim can of course be written a bit more efficient and fast, which would have as result that the computation time for a comparison between two users would decrease. So, the number 28.5 years can be probably be smaller for using a brute force method. However, it would still be significantly orders slower than using the minhashing/LSH method we will do in the second part of this assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
